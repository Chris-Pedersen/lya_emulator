{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/apps/anaconda/python3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5)\n",
      "Beginning to initialise LikelihoodClass at 2018-11-06 13:39:31.784696\n",
      "Looking for spectra in /share/data2/keir/Simulations/refinement_tight_validation/ns0.97As2.2e-09heat_slope0.05heat_amp1hub0.69/output\n",
      "Found spectra in None\n",
      "Found spectra in None\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7d588448d0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7d5994b8d0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7d59952048>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7d59952668>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7d59952710>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7d59958438>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7d58844908>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7d59958390>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7d59958ba8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7d599600b8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7d59960208>\n",
      "Looking for spectra in /share/data2/keir/Simulations/refinement_tight/ns0.93As2.3e-09heat_slope0.11heat_amp0.89hub0.72/output\n",
      "Found spectra in None\n",
      "Found spectra in None\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7d59960e48>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7d59976198>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7d599764a8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7d59976dd8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7d59976da0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f613e6240>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f613e6320>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f613e6b70>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f613ea438>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f613ea3c8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f613ea4e0>\n",
      "Looking for spectra in /share/data2/keir/Simulations/refinement_tight/ns1As1.7e-09heat_slope-0.33heat_amp0.67hub0.68/output\n",
      "Found spectra in None\n",
      "Found spectra in None\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f613f9828>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f613f9240>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f613f9630>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f613f9668>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614033c8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61403390>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61403438>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61403ba8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6140c0b8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6140c198>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6140c5f8>\n",
      "Looking for spectra in /share/data2/keir/Simulations/refinement_tight/ns0.9As2.5e-09heat_slope0heat_amp1hub0.63/output\n",
      "Found spectra in None\n",
      "Found spectra in None\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61416940>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61416390>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614162e8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61416b70>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6141c4a8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6141c160>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6141c550>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6141ccc0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6142b208>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6142b2b0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6142b710>\n",
      "Looking for spectra in /share/data2/keir/Simulations/refinement_tight/ns0.95As2.1e-09heat_slope-0.44heat_amp1.2hub0.77/output\n",
      "Found spectra in None\n",
      "Found spectra in None\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61431a58>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614314a8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61431400>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61431908>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6143a208>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6143a550>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6143a668>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6143af98>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614432b0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614433c8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61443828>\n",
      "Looking for spectra in /share/data2/keir/Simulations/refinement_tight/ns0.98As1.5e-09heat_slope-0.11heat_amp1.3hub0.66/output\n",
      "Found spectra in None\n",
      "Found spectra in None\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6144fb70>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6144f5c0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6144f128>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6144fda0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61452278>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61452320>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61452780>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61460438>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614603c8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614604e0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61460c50>\n",
      "Looking for spectra in /share/data2/keir/Simulations/refinement_tight/ns0.87As2.7e-09heat_slope-0.22heat_amp0.56hub0.79/output\n",
      "Found spectra in None\n",
      "Found spectra in None\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6146ac88>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6146a6d8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6146a198>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61478400>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61478390>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61478780>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61478ba8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614820b8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61482198>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614825f8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61482d68>\n",
      "Looking for spectra in /share/data2/keir/Simulations/refinement_tight/ns0.81As1.3e-09heat_slope0.22heat_amp1.4hub0.74/output\n",
      "Found spectra in None\n",
      "Found spectra in None\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61488da0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61488860>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61488668>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614910f0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61491438>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61491550>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61491cc0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6149e1d0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6149e2b0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6149e710>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614a9400>\n",
      "Looking for spectra in /share/data2/keir/Simulations/refinement_tight/ns0.84As1.9e-09heat_slope0.33heat_amp0.78hub0.69/output\n",
      "Found spectra in None\n",
      "Found spectra in None\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614a9f28>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614a9908>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614a93c8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614b3208>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614b3550>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614b3668>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614b3dd8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614bf320>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614bf3c8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614bfb38>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614bd080>\n",
      "Looking for spectra in /share/data2/keir/Simulations/refinement_tight/ns1As2.9e-09heat_slope0.44heat_amp1.1hub0.61/output\n",
      "Found spectra in None\n",
      "Found spectra in None\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614bdf28>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614bd588>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614bde10>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614cd2b0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614cd6a0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614cd780>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614d3438>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614d33c8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614d3d30>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614d3e10>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614e0198>\n",
      "Looking for spectra in /share/data2/keir/Simulations/refinement_tight/ns0.99As1.4e-09heat_slope-0.1heat_amp1.3hub0.65/output\n",
      "Found spectra in None\n",
      "Found spectra in None\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614e0f60>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614e0b38>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614e4438>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614e47f0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614e44a8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614e4ba8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614f30b8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614f34a8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614f35f8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614f3d68>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614fc278>\n",
      "Looking for spectra in /share/data2/keir/Simulations/refinement_tight/ns0.95As2.3e-09heat_slope0.13heat_amp0.91hub0.7/output\n",
      "Found spectra in None\n",
      "Found spectra in None\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614fceb8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f614fc7b8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f615020b8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61502080>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f615024a8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61502cc0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61513208>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f615132b0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61513710>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6151a400>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6151a358>\n",
      "Looking for spectra in /share/data2/keir/Simulations/refinement_tight/ns0.96As2.2e-09heat_slope0.15heat_amp0.92hub0.69/output\n",
      "Found spectra in None\n",
      "Found spectra in None\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6151aef0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6151ac18>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61626160>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f616262b0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61626668>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61626dd8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6162d710>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6162d7b8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6162db38>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61639080>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f616398d0>\n",
      "Looking for spectra in /share/data2/keir/Simulations/refinement_tight/ns0.96As2.2e-09heat_slope0.19heat_amp0.95hub0.7/output\n",
      "Found spectra in None\n",
      "Found spectra in None\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61639f28>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61639e80>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6163f6d8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6163f390>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6163f7b8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6164a438>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6164a4e0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6164a828>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6164ac50>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61653160>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61653198>\n",
      "Looking for spectra in /share/data2/keir/Simulations/refinement_tight/ns0.97As2.3e-09heat_slope0.17heat_amp1hub0.69/output\n",
      "Found spectra in None\n",
      "Found spectra in None\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61653f98>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f61653e10>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6165e5f8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6165e588>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f6165eba8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f62f650b8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f62f651d0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f62f65d68>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f62f65a58>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f62f6c278>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f62f6cb00>\n",
      "Looking for spectra in /share/data2/keir/Simulations/refinement_tight/ns0.97As2.3e-09heat_slope0.15heat_amp0.99hub0.68/output\n",
      "Found spectra in None\n",
      "Found spectra in None\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f62f766a0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f62f76400>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f62f76128>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f62f764e0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f62f76e80>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f62f81240>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f62f812e8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f62f81710>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f62f8f400>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f62f8f358>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f62f8fc18>\n",
      "Looking for spectra in /share/data2/keir/Simulations/refinement_tight/ns0.96As2.3e-09heat_slope0.085heat_amp0.98hub0.69/output\n",
      "Found spectra in None\n",
      "Found spectra in None\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f62f967b8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f62f965c0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f62f960f0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f62f96630>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f62f96dd8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f647a0320>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f647a0b70>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f647a0c88>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f647aa080>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f647aa128>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f647aa588>\n",
      "Looking for spectra in /share/data2/keir/Simulations/refinement_tight/ns0.96As2.3e-09heat_slope0.22heat_amp1.1hub0.69/output\n",
      "Found spectra in None\n",
      "Found spectra in None\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f647b78d0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f647b7240>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f647b72b0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f647b76d8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f647be438>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f647be3c8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f647be4e0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f647bec50>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f647c7160>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f647c7240>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f647c76a0>\n",
      "Looking for spectra in /share/data2/keir/Simulations/refinement_tight/ns0.98As2.4e-09heat_slope0.081heat_amp1hub0.68/output\n",
      "Found spectra in None\n",
      "Found spectra in None\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f647d19e8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f647d1358>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f647d17f0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f647d1d30>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f647da0b8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f647da198>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f647da5f8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f647dad68>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f65fe52b0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f65fe5358>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b7f65fe57b8>\n",
      "Number of redshifts for emulator generation = 11\n",
      "  \u001b[1mlinear.  \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mvariances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1msum.            \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mlinear.variances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.variance    \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.lengthscale \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i      f              |g|        \n",
      "    00s05  0008  -3.461675e+04   3.978640e+06 \n",
      "    00s16  0025  -3.531596e+04   1.302843e+04 \n",
      "    00s35  0058  -3.534729e+04   1.633370e+00 \n",
      "Runtime:     00s35\n",
      "Optimization status: Converged\n",
      "\n",
      "\n",
      "Name : GP regression\n",
      "Objective : -35347.291333944435\n",
      "Number of Parameters : 4\n",
      "Number of Optimization Parameters : 4\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mGP_regression.         \u001b[0;0m  |                  value  |  constraints  |  priors\n",
      "  \u001b[1msum.linear.variances   \u001b[0;0m  |  3.521115328925176e-52  |      +ve      |        \n",
      "  \u001b[1msum.rbf.variance       \u001b[0;0m  |      593.7039916756343  |      +ve      |        \n",
      "  \u001b[1msum.rbf.lengthscale    \u001b[0;0m  |     3.0037735710933364  |      +ve      |        \n",
      "  \u001b[1mGaussian_noise.variance\u001b[0;0m  |   5.19603738186991e-68  |      +ve      |        \n",
      "  \u001b[1mlinear.  \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mvariances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1msum.            \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mlinear.variances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.variance    \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.lengthscale \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i      f              |g|        \n",
      "    00s04  0009  -3.735204e+04   1.034606e+06 \n",
      "    00s15  0027  -3.773006e+04   1.249173e+02 \n",
      "    00s19  0032  -3.773076e+04   1.418077e-02 \n",
      "    00s42  0071  -3.773076e+04   1.418077e-02 \n",
      "Runtime:     00s42\n",
      "Optimization status: Converged\n",
      "\n",
      "\n",
      "Name : GP regression\n",
      "Objective : -37730.76126033487\n",
      "Number of Parameters : 4\n",
      "Number of Optimization Parameters : 4\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mGP_regression.         \u001b[0;0m  |                  value  |  constraints  |  priors\n",
      "  \u001b[1msum.linear.variances   \u001b[0;0m  |     0.2815211985934659  |      +ve      |        \n",
      "  \u001b[1msum.rbf.variance       \u001b[0;0m  |      41.57048424822081  |      +ve      |        \n",
      "  \u001b[1msum.rbf.lengthscale    \u001b[0;0m  |     2.5357169803233575  |      +ve      |        \n",
      "  \u001b[1mGaussian_noise.variance\u001b[0;0m  |  5.029096917090315e-16  |      +ve      |        \n",
      "  \u001b[1mlinear.  \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mvariances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1msum.            \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mlinear.variances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.variance    \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.lengthscale \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i      f              |g|        \n",
      "    00s05  0009  -3.747464e+04   3.154146e+06 \n",
      "    00s16  0027  -3.784781e+04   2.943029e+02 \n",
      "    00s19  0032  -3.784803e+04   2.117612e-02 \n",
      "    00s50  0100  -3.784812e+04   8.865628e-02 \n",
      "Runtime:     00s50\n",
      "Optimization status: Errorb'ABNORMAL_TERMINATION_IN_LNSRCH'\n",
      "\n",
      "\n",
      "Name : GP regression\n",
      "Objective : -37848.12455405188\n",
      "Number of Parameters : 4\n",
      "Number of Optimization Parameters : 4\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mGP_regression.         \u001b[0;0m  |                  value  |  constraints  |  priors\n",
      "  \u001b[1msum.linear.variances   \u001b[0;0m  |   5.99097591907887e-05  |      +ve      |        \n",
      "  \u001b[1msum.rbf.variance       \u001b[0;0m  |     104.24298308061404  |      +ve      |        \n",
      "  \u001b[1msum.rbf.lengthscale    \u001b[0;0m  |      2.961281871725496  |      +ve      |        \n",
      "  \u001b[1mGaussian_noise.variance\u001b[0;0m  |  6.934418239680951e-22  |      +ve      |        \n",
      "  \u001b[1mlinear.  \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mvariances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1msum.            \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mlinear.variances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.variance    \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.lengthscale \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i      f              |g|        \n",
      "    00s01  0002  -3.634032e+04   4.192180e+07 \n",
      "    00s05  0009  -3.779579e+04   6.463354e+05 \n",
      "    00s16  0027  -3.811733e+04   2.086592e+03 \n",
      "    00s19  0031  -3.811852e+04   1.508882e-01 \n",
      "    00s51  0090  -3.811852e+04   1.783538e+00 \n",
      "Runtime:     00s51\n",
      "Optimization status: Errorb'ABNORMAL_TERMINATION_IN_LNSRCH'\n",
      "\n",
      "\n",
      "Name : GP regression\n",
      "Objective : -38118.52558641421\n",
      "Number of Parameters : 4\n",
      "Number of Optimization Parameters : 4\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mGP_regression.         \u001b[0;0m  |                  value  |  constraints  |  priors\n",
      "  \u001b[1msum.linear.variances   \u001b[0;0m  |     0.7076429062727465  |      +ve      |        \n",
      "  \u001b[1msum.rbf.variance       \u001b[0;0m  |     106.69781342144081  |      +ve      |        \n",
      "  \u001b[1msum.rbf.lengthscale    \u001b[0;0m  |     3.1220706620634893  |      +ve      |        \n",
      "  \u001b[1mGaussian_noise.variance\u001b[0;0m  |  7.197208961800242e-18  |      +ve      |        \n",
      "  \u001b[1mlinear.  \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mvariances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1msum.            \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mlinear.variances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.variance    \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.lengthscale \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i      f              |g|        \n",
      "    00s01  0002  -3.769207e+04   1.178495e+07 \n",
      "    00s05  0008  -3.818206e+04   8.334374e+05 \n",
      "    00s14  0024  -3.866712e+04   2.689238e+01 \n",
      "    00s35  0068  -3.866714e+04   1.538912e-02 \n",
      "Runtime:     00s35\n",
      "Optimization status: Errorb'ABNORMAL_TERMINATION_IN_LNSRCH'\n",
      "\n",
      "\n",
      "Name : GP regression\n",
      "Objective : -38667.14272993812\n",
      "Number of Parameters : 4\n",
      "Number of Optimization Parameters : 4\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mGP_regression.         \u001b[0;0m  |                  value  |  constraints  |  priors\n",
      "  \u001b[1msum.linear.variances   \u001b[0;0m  |  8.338144936961322e-06  |      +ve      |        \n",
      "  \u001b[1msum.rbf.variance       \u001b[0;0m  |      40.35184461299825  |      +ve      |        \n",
      "  \u001b[1msum.rbf.lengthscale    \u001b[0;0m  |     2.8516052614549188  |      +ve      |        \n",
      "  \u001b[1mGaussian_noise.variance\u001b[0;0m  |  3.819878231470792e-15  |      +ve      |        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[1mlinear.  \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mvariances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1msum.            \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mlinear.variances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.variance    \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.lengthscale \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i      f              |g|        \n",
      "    00s04  0007  -3.823548e+04   3.709556e+05 \n",
      "    00s13  0022  -3.878865e+04   4.845296e+02 \n",
      "    00s16  0026  -3.878943e+04   1.618895e-01 \n",
      "    00s18  0030  -3.878943e+04   6.888978e-07 \n",
      "Runtime:     00s18\n",
      "Optimization status: Converged\n",
      "\n",
      "\n",
      "Name : GP regression\n",
      "Objective : -38789.43126104631\n",
      "Number of Parameters : 4\n",
      "Number of Optimization Parameters : 4\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mGP_regression.         \u001b[0;0m  |                   value  |  constraints  |  priors\n",
      "  \u001b[1msum.linear.variances   \u001b[0;0m  |   5.130255513979641e-07  |      +ve      |        \n",
      "  \u001b[1msum.rbf.variance       \u001b[0;0m  |       41.40049783351095  |      +ve      |        \n",
      "  \u001b[1msum.rbf.lengthscale    \u001b[0;0m  |      2.8981228058174637  |      +ve      |        \n",
      "  \u001b[1mGaussian_noise.variance\u001b[0;0m  |  3.2138414762049364e-15  |      +ve      |        \n",
      "  \u001b[1mlinear.  \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mvariances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1msum.            \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mlinear.variances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.variance    \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.lengthscale \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i      f              |g|        \n",
      "    00s01  0004  -3.837887e+04   4.923147e+04 \n",
      "    00s06  0014  -3.889067e+04   3.036154e+04 \n",
      "    00s13  0025  -3.897433e+04   4.927097e-01 \n",
      "    00s19  0034  -3.897433e+04   4.894411e-01  \n",
      "    00s46  0078  -3.897433e+04   4.894411e-01 \n",
      "Runtime:     00s46\n",
      "Optimization status: Errorb'ABNORMAL_TERMINATION_IN_LNSRCH'\n",
      "\n",
      "\n",
      "Name : GP regression\n",
      "Objective : -38974.32763230159\n",
      "Number of Parameters : 4\n",
      "Number of Optimization Parameters : 4\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mGP_regression.         \u001b[0;0m  |                   value  |  constraints  |  priors\n",
      "  \u001b[1msum.linear.variances   \u001b[0;0m  |  4.3085340875900175e-08  |      +ve      |        \n",
      "  \u001b[1msum.rbf.variance       \u001b[0;0m  |       38.21987790735076  |      +ve      |        \n",
      "  \u001b[1msum.rbf.lengthscale    \u001b[0;0m  |      2.9344771231011557  |      +ve      |        \n",
      "  \u001b[1mGaussian_noise.variance\u001b[0;0m  |  5.1234893277187074e-15  |      +ve      |        \n",
      "  \u001b[1mlinear.  \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mvariances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1msum.            \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mlinear.variances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.variance    \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.lengthscale \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i      f              |g|        \n",
      "    00s04  0007  -3.615181e+04   5.107414e+04 \n",
      "    00s14  0022  -3.711037e+04   1.516898e+03 \n",
      "    00s19  0030  -3.716770e+04   1.323033e+04 \n",
      "Runtime:     00s19\n",
      "Optimization status: Converged\n",
      "\n",
      "\n",
      "Name : GP regression\n",
      "Objective : -37167.70200644249\n",
      "Number of Parameters : 4\n",
      "Number of Optimization Parameters : 4\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mGP_regression.         \u001b[0;0m  |                  value  |  constraints  |  priors\n",
      "  \u001b[1msum.linear.variances   \u001b[0;0m  |     0.7519986097746976  |      +ve      |        \n",
      "  \u001b[1msum.rbf.variance       \u001b[0;0m  |      335.1162422121369  |      +ve      |        \n",
      "  \u001b[1msum.rbf.lengthscale    \u001b[0;0m  |      3.335899355023705  |      +ve      |        \n",
      "  \u001b[1mGaussian_noise.variance\u001b[0;0m  |  2.324079461508749e-45  |      +ve      |        \n",
      "  \u001b[1mlinear.  \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mvariances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1msum.            \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mlinear.variances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.variance    \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.lengthscale \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i      f              |g|        \n",
      "    00s02  0003  -3.599257e+04   4.799892e+05 \n",
      "    00s07  0011  -3.666752e+04   1.499642e+05 \n",
      "    00s14  0021  -3.706814e+04   5.879889e+03 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /share/apps/anaconda/python3.6/lib/python3.6/site-packages/GPy/kern/src/stationary.py:198: RuntimeWarning:invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    00s19  0028  -3.717171e+04   1.511489e+04 \n",
      "    00s38  0061  -3.718698e+04   2.347159e+00 \n",
      "Runtime:     00s38\n",
      "Optimization status: Converged\n",
      "\n",
      "\n",
      "Name : GP regression\n",
      "Objective : -37186.97569775534\n",
      "Number of Parameters : 4\n",
      "Number of Optimization Parameters : 4\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mGP_regression.         \u001b[0;0m  |                   value  |  constraints  |  priors\n",
      "  \u001b[1msum.linear.variances   \u001b[0;0m  |  2.1111786257872852e-16  |      +ve      |        \n",
      "  \u001b[1msum.rbf.variance       \u001b[0;0m  |        734.776446899055  |      +ve      |        \n",
      "  \u001b[1msum.rbf.lengthscale    \u001b[0;0m  |       3.723354881095033  |      +ve      |        \n",
      "  \u001b[1mGaussian_noise.variance\u001b[0;0m  |  1.897380736015389e-110  |      +ve      |        \n",
      "  \u001b[1mlinear.  \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mvariances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1msum.            \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mlinear.variances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.variance    \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.lengthscale \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i      f              |g|        \n",
      "    00s05  0008  -3.509328e+04   3.750415e+06 \n",
      "    00s15  0025  -3.633649e+04   8.677561e+03 \n",
      "    00s19  0031   1.169565e+04   4.337177e+08 \n",
      "    00s49  0089  -3.641542e+04   1.348212e+02 \n",
      "Runtime:     00s49\n",
      "Optimization status: Errorb'ABNORMAL_TERMINATION_IN_LNSRCH'\n",
      "\n",
      "\n",
      "Name : GP regression\n",
      "Objective : -36415.45364041859\n",
      "Number of Parameters : 4\n",
      "Number of Optimization Parameters : 4\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mGP_regression.         \u001b[0;0m  |                   value  |  constraints  |  priors\n",
      "  \u001b[1msum.linear.variances   \u001b[0;0m  |   8.219117789058117e-60  |      +ve      |        \n",
      "  \u001b[1msum.rbf.variance       \u001b[0;0m  |      2669.0829553120257  |      +ve      |        \n",
      "  \u001b[1msum.rbf.lengthscale    \u001b[0;0m  |       4.177671828242919  |      +ve      |        \n",
      "  \u001b[1mGaussian_noise.variance\u001b[0;0m  |  7.467446770406299e-179  |      +ve      |        \n",
      "  \u001b[1mlinear.  \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mvariances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1msum.            \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mlinear.variances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.variance    \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.lengthscale \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i      f              |g|        \n",
      "    00s04  0007  -3.473997e+04   3.679292e+06 \n",
      "    00s13  0022  -3.598359e+04   5.170421e+04 \n",
      "    00s19  0032  -3.610791e+04   4.727202e+03 \n",
      "    00s67  0131  -3.615363e+04   4.484592e-03 \n",
      "Runtime:     00s67\n",
      "Optimization status: Errorb'ABNORMAL_TERMINATION_IN_LNSRCH'\n",
      "\n",
      "\n",
      "Name : GP regression\n",
      "Objective : -36153.57246054565\n",
      "Number of Parameters : 4\n",
      "Number of Optimization Parameters : 4\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mGP_regression.         \u001b[0;0m  |                   value  |  constraints  |  priors\n",
      "  \u001b[1msum.linear.variances   \u001b[0;0m  |   2.03252433846366e-103  |      +ve      |        \n",
      "  \u001b[1msum.rbf.variance       \u001b[0;0m  |       3223.058620355737  |      +ve      |        \n",
      "  \u001b[1msum.rbf.lengthscale    \u001b[0;0m  |      4.1570126427052045  |      +ve      |        \n",
      "  \u001b[1mGaussian_noise.variance\u001b[0;0m  |  2.484970726932628e-231  |      +ve      |        \n"
     ]
    }
   ],
   "source": [
    "run /home/keir/Software/lya_emulator/main.py /share/data2/keir/Simulations /home/keir/Plots/Emulator refinement_tight_validation_refine4 /home/keir/Data/emulator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run /home/keir/Software/lya_emulator/main.py /home/keir/Data/emulator /home/keir/Plots/Emulator hot_cold_training3_rescale_2000 /home/keir/Data/emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import multiprocessing as mu\n",
    "#import corner as co\n",
    "#import seaborn as sb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = np.loadtxt('/home/keir/Data/emulator/AA0.97BB1.3_chain_refinement_tight_validation_refine9.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.50e-01,  2.50e-01],\n",
       "       [ 7.50e-01,  1.25e+00],\n",
       "       [ 8.00e-01,  1.05e+00],\n",
       "       [ 1.20e-09,  3.00e-09],\n",
       "       [-5.00e-01,  5.00e-01],\n",
       "       [ 5.00e-01,  1.50e+00],\n",
       "       [ 6.00e-01,  8.00e-01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].param_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.4e-01  1.0e+00]\n",
      " [ 1.5e-09  2.7e-09]\n",
      " [-3.3e-01  3.3e-01]\n",
      " [ 6.7e-01  1.3e+00]\n",
      " [ 6.3e-01  7.7e-01]]\n",
      "[[0.16       0.8       ]\n",
      " [0.16666667 0.83333333]\n",
      " [0.17       0.83      ]\n",
      " [0.17       0.8       ]\n",
      " [0.15       0.85      ]]\n",
      "[(0.1599999999999997, 0.7999999999999998), (0.16666666666666666, 0.8333333333333335), (0.16999999999999998, 0.8300000000000001), (0.17000000000000004, 0.8), (0.15000000000000008, 0.8499999999999999)]\n"
     ]
    }
   ],
   "source": [
    "n_process = 10\n",
    "n_parameters = 7\n",
    "n_marginalised_parameters = 2\n",
    "\n",
    "#optimisation_bounds_unscaled = np.array([[0.81, 1.], [1.3e-9, 2.9e-9], [-0.44, 0.44], [0.56, 1.4], [0.61, 0.79]]) #Convex hull_0\n",
    "#optimisation_bounds_unscaled = np.array([[0.825, 1.], [1.4e-9, 2.8e-9], [-0.385, 0.385], [0.615, 1.35], [0.62, 0.78]]) #Convex hull_1\n",
    "optimisation_bounds_unscaled = np.array([[0.84, 1.], [1.5e-9, 2.7e-9], [-0.33, 0.33], [0.67, 1.3], [0.63, 0.77]]) #Convex hull_2\n",
    "#optimisation_bounds_unscaled = np.array([[0.915, 0.985], [1.5e-9, 2.5e-9], [-0.2, 0.2], [0.8, 1.3], [0.65, 0.73]]) #Edge\n",
    "#optimisation_bounds_unscaled = np.array([[0.93, 0.98], [1.5e-9, 2.5e-9], [-0.2, 0.2], [0.9, 1.3], [0.655, 0.725]]) #4s\n",
    "\n",
    "#refinement_big\n",
    "#optimisation_bounds_unscaled = np.array([[0.91, 0.98], [1.6e-9, 2.7e-9], [-0.34, 0.34], [0.66, 1.3], [0.66, 0.74]]) #CH2\n",
    "print(optimisation_bounds_unscaled)\n",
    "\n",
    "optimisation_bounds_array = np.zeros_like(optimisation_bounds_unscaled)\n",
    "optimisation_bounds_array[:, 0] = map_to_unit_cube(optimisation_bounds_unscaled[:, 0], output[0].param_limits[n_marginalised_parameters:])\n",
    "optimisation_bounds_array[:, 1] = map_to_unit_cube(optimisation_bounds_unscaled[:, 1], output[0].param_limits[n_marginalised_parameters:])\n",
    "\n",
    "#optimisation_bounds_array = np.ones((n_parameters - n_marginalised_parameters, 2))\n",
    "#optimisation_bounds_array[:, 0] *= 1.e-7\n",
    "#optimisation_bounds_array[:, 1] *= 1. - 1.e-7\n",
    "\n",
    "print(optimisation_bounds_array)\n",
    "optimisation_bounds = [tuple(optimisation_bounds_array[i]) for i in range(n_parameters - n_marginalised_parameters)]\n",
    "print(optimisation_bounds)\n",
    "\n",
    "starting_positions = np.array([npr.uniform(low=optimisation_bounds_array[:, 0], high=optimisation_bounds_array[:, 1]) for i in range(n_process)])\n",
    "#print(starting_positions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.60299840e-01 2.37272512e-09 5.21959093e-02 9.83503118e-01\n",
      " 6.86868963e-01]\n",
      "[ 8.4e-01  1.5e-09 -3.3e-01  6.7e-01  6.3e-01]\n",
      "[9.50554905e-01 2.40261529e-09 4.87225716e-02 9.54722615e-01\n",
      " 6.95175474e-01]\n",
      "[ 8.4e-01  1.5e-09 -3.3e-01  6.7e-01  6.3e-01]\n",
      "[9.57270326e-01 2.27761315e-09 1.07533568e-01 9.11184759e-01\n",
      " 6.97307870e-01]\n",
      "[9.67183011e-01 2.28560208e-09 1.26859958e-01 9.96034649e-01\n",
      " 6.73919071e-01]\n",
      "[8.40000000e-01 2.70000000e-09 3.30000000e-01 1.30000000e+00\n",
      " 6.41326843e-01]\n",
      "[1.0e+00 2.7e-09 3.3e-01 1.3e+00 7.7e-01]\n",
      "[9.76690421e-01 2.33981819e-09 1.38631348e-01 1.00941996e+00\n",
      " 6.83931090e-01]\n",
      "[9.73717617e-01 2.30606344e-09 1.78769478e-01 9.99295524e-01\n",
      " 6.82960460e-01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing as mg\n",
    "mg.set_start_method('forkserver', force=True)\n",
    "\n",
    "import acquisition as ac\n",
    "\n",
    "#starting_positions = 1.e-7 + npr.rand(n_process, n_parameters - n_marginalised_parameters) * (1. - 2.e-7)\n",
    "#optimisation_bounds = [(1.e-7, 1. - 1.e-7) for i in range(n_parameters - n_marginalised_parameters)]\n",
    "#integration_bounds = [list(output[0].param_limits[0]), list(output[0].param_limits[1])]\n",
    "#integration_bounds = [[-0.05, 0.1], [0.92, 1.02]]\n",
    "#integration_bounds = [[-0.04, 0.1], [0.96, 1.02]]\n",
    "integration_bounds = [[-0.07, 0.07], [0.925, 1.]]\n",
    "argument_list = [(starting_positions[i], output[0], optimisation_bounds, 0.00004, 1., integration_bounds) for i in range(n_process)]\n",
    "\n",
    "pool_instance = mg.Pool(n_process)\n",
    "optimisation_output = pool_instance.map(ac.optimise_acquisition_function_parallel, argument_list)\n",
    "\n",
    "[print(map_from_unit_cube(optimisation_output[i].x, output[0].param_limits[n_marginalised_parameters:])) for i in range(n_process)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1388.2378417237337\n",
      "1243.630611888192\n",
      "1391.2364247385478\n",
      "1243.630611888192\n",
      "1390.0704548981646\n",
      "1387.6604211617976\n",
      "1801.1953528613485\n",
      "1817.6841615856665\n",
      "1388.412275652582\n",
      "1387.5071070383262\n",
      "[8.98239339e-01 2.14538189e-09 2.97189599e-01 6.83304050e-01\n",
      " 7.52964397e-01]\n",
      "[ 9.58964417e-01  2.54512607e-09 -5.20550738e-02  9.51401544e-01\n",
      "  7.03615009e-01]\n",
      "[9.47699064e-01 2.26962452e-09 1.43362872e-01 7.22564025e-01\n",
      " 6.87997192e-01]\n",
      "[ 8.61673515e-01  1.63556721e-09 -2.83457398e-01  9.91793267e-01\n",
      "  7.42478510e-01]\n",
      "[ 9.31345613e-01  2.42565495e-09 -1.81389722e-01  6.91972016e-01\n",
      "  7.15499841e-01]\n",
      "[9.01446237e-01 2.17669627e-09 1.95298183e-01 9.05653723e-01\n",
      " 7.10072644e-01]\n",
      "[9.90798030e-01 2.54291451e-09 1.98531143e-01 1.01596061e+00\n",
      " 7.63975049e-01]\n",
      "[ 9.06334998e-01  1.56963673e-09 -3.91139918e-02  1.06376093e+00\n",
      "  6.95508323e-01]\n",
      "[ 8.95700104e-01  2.12881829e-09 -5.11195216e-02  1.19591341e+00\n",
      "  7.04657455e-01]\n",
      "[9.83480257e-01 2.15822508e-09 2.05771939e-01 1.28003086e+00\n",
      " 6.53766182e-01]\n",
      "1 [ 8.4e-01  1.5e-09 -3.3e-01  6.7e-01  6.3e-01]\n"
     ]
    }
   ],
   "source": [
    "[print(optimisation_output[i].fun) for i in range(n_process)]\n",
    "\n",
    "[print(map_from_unit_cube(starting_positions[i], output[0].param_limits[n_marginalised_parameters:])) for i in range(n_process)]\n",
    "\n",
    "best_process = np.argmin(np.array([optimisation_output[i].fun for i in range(n_process)]))\n",
    "print(best_process, map_from_unit_cube(optimisation_output[best_process].x, output[0].param_limits[n_marginalised_parameters:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9.77121110e-01 2.33006571e-09 1.77141856e-01 1.00350071e+00\n",
    "# 6.85706122e-01 #0.00001\n",
    "#9.70205434e-01 2.32495094e-09 1.10423177e-01 9.96588837e-01\n",
    "# 6.81885764e-01 #0.00003\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import corner as co\n",
    "\n",
    "#corner_plot_limits = [[0.92, 0.98], [2.2e-09, 2.4e-09], [0., 0.16], [0.84, 1.12], [0.68, 0.73]]\n",
    "corner_plot_limits = [[0.945, 0.978], [2.18e-09, 2.32e-09], [0.04, 0.26], [0.86, 1.1], [0.675, 0.715]]\n",
    "\n",
    "corner_plot_labels = [r'$d\\tau_0$', r'$\\tau_0$', r'$n_s$', r'$A_s$', 'heat slope', 'heat amp', 'hub']\n",
    "\n",
    "figure = co.corner(posterior_samples[:, n_marginalised_parameters:], labels=corner_plot_labels[n_marginalised_parameters:], truths=np.concatenate(([], map_from_unit_cube(optimisation_output[best_process].x, output[0].param_limits[n_marginalised_parameters:]))))\n",
    "#figure = co.corner(posterior_samples[:, n_marginalised_parameters:], labels=corner_plot_labels[n_marginalised_parameters:], truths=np.concatenate(([], refinement_simulation + random_gauss)))\n",
    "\n",
    "###Add truths\n",
    "# Extract the axes\n",
    "value1 = [0.974, 2.24e-09, 0.0509, 1.09, 0.685]\n",
    "ndim = n_parameters - n_marginalised_parameters\n",
    "axes = np.array(figure.axes).reshape((ndim, ndim))\n",
    "\n",
    "# Loop over the diagonal\n",
    "for i in range(ndim):\n",
    "    ax = axes[i, i]\n",
    "    ax.axvline(value1[i], color=\"g\")\n",
    "    #ax.axvline(value2[i], color=\"r\")\n",
    "\n",
    "    #ax.set_xlim(corner_plot_limits[i])\n",
    "\n",
    "# Loop over the histograms\n",
    "for yi in range(ndim):\n",
    "    for xi in range(yi):\n",
    "        ax = axes[yi, xi]\n",
    "        ax.axvline(value1[xi], color=\"g\")\n",
    "        #ax.axvline(value2[xi], color=\"r\")\n",
    "        ax.axhline(value1[yi], color=\"g\")\n",
    "        #ax.axhline(value2[yi], color=\"r\")\n",
    "        ax.plot(value1[xi], value1[yi], \"sg\")\n",
    "        #ax.plot(value2[xi], value2[yi], \"sr\")\n",
    "\n",
    "        #ax.set_xlim(corner_plot_limits[xi])\n",
    "        #ax.set_ylim(corner_plot_limits[yi])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_lims = np.array([[-2.50e-01,  2.50e-01],\n",
    "       [ 7.50e-01,  1.25e+00],\n",
    "       [ 8.00e-01,  1.05e+00],\n",
    "       [ 1.20e-09,  3.00e-09],\n",
    "       [-5.00e-01,  5.00e-01],\n",
    "       [ 5.00e-01,  1.50e+00],\n",
    "       [ 6.00e-01,  8.00e-01]])\n",
    "\n",
    "print(p_lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refinement_simulation = map_from_unit_cube(optimisation_output[best_process].x, output[0].param_limits[n_marginalised_parameters:])\n",
    "\n",
    "random_width = 0.07 * (p_lims[2:, 1] - p_lims[2:, 0]) #0.05 (2)\n",
    "print(random_width)\n",
    "\n",
    "random_gauss = np.random.normal(scale=random_width)\n",
    "print(random_gauss)\n",
    "\n",
    "#print(np.array([9.83826422e-01, 1.53457828e-09, -1.12879347e-01, 1.30000000e+00, 6.61319870e-01]))\n",
    "#print(np.array([9.83826422e-01, 1.53457828e-09, -1.12879347e-01, 1.30000000e+00, 6.61319870e-01]) + random_gauss)\n",
    "\n",
    "print(refinement_simulation)\n",
    "print(refinement_simulation + random_gauss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisition_function_tau0_amp = output[0].make_grid_acquisition_function(4, 5, samples=30000, nu=1., exploitation_weight=None)\n",
    "acquisition_function_tau0_amp[acquisition_function_tau0_amp == 0.] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisition_function_tau0_amp_exploit = output.make_grid_acquisition_function(0, 2, samples=1000, nu=0., exploitation_weight=1.)\n",
    "acquisition_function_tau0_amp_exploit[acquisition_function_tau0_amp_exploit == 0.] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contour(np.log10(acquisition_function_tau0_amp).T, 100, extent=[0.75, 1.25, 0.8, 1.2], origin='image')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.exp(acquisition_function_tau0_amp).T, extent=[-0.25, 0.25, 0.8, 1.2])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 18))\n",
    "plt.imshow(np.exp(acquisition_function_tau0_amp_exploit - np.nanmax(acquisition_function_tau0_amp_exploit)).T, extent=[-0.25, 0.25, 0.8, 1.2])\n",
    "plt.colorbar()\n",
    "#plt.scatter(0.95, 0.95, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisition_function_exploit = output.acquisition_function_GP_UCB_marginalised_mean_flux(np.array([0.95,]), nu=1., exploitation_weight=0.)\n",
    "acquisition_function_exploit = output.acquisition_function_GP_UCB_marginalised_mean_flux(np.array([0.9,]), nu=1., exploitation_weight=0.)\n",
    "acquisition_function_exploit = output.acquisition_function_GP_UCB_marginalised_mean_flux(np.array([1.,]), nu=1., exploitation_weight=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisition_function_exploit = output.acquisition_function_GP_UCB_marginalised_mean_flux(np.array([0.95,]), nu=1., exploitation_weight=1.)\n",
    "acquisition_function_exploit = output.acquisition_function_GP_UCB_marginalised_mean_flux(np.array([0.95,]), nu=0., exploitation_weight=1.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output[0].acquisition_function_GP_UCB_marginalised_mean_flux(np.array([0.81,]), nu=1., exploitation_weight=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(output[0]._get_emulator_error_averaged_mean_flux(np.array([0.81,]))))\n",
    "\n",
    "_ = output[0].likelihood(np.array([0., 0.95, 0.81]))\n",
    "print(np.mean(output[0].emulated_flux_power_std[0]))\n",
    "\n",
    "print(np.mean(output[0].emulated_flux_power_std[0]) / np.mean(output[0].emulated_flux_power[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.cur_results.flatchain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.cur_results.get_lnprob(np.array([0., 0.95, 0.95]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(posterior_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_output = sb.kdeplot(posterior_samples[:, 2]).get_lines()[0].get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_output = plt.hist(posterior_samples[:, 2], bins='auto', normed=True, histtype='step', log=True)\n",
    "print(histogram_output)\n",
    "plt.axvline(x=0.92)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(histogram_output[0].shape)\n",
    "print(histogram_output[1].shape)\n",
    "print(histogram_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#n_samples = 200\n",
    "parameter_samples = (histogram_output[1][:-1] + histogram_output[1][1:]) / 2. #np.linspace(output[0].param_limits[2, 0], output[0].param_limits[2, 1], num=n_samples)\n",
    "acquisition_function_exploit_array = np.zeros_like(parameter_samples)\n",
    "for i in range(parameter_samples.shape[0]):\n",
    "    acquisition_function_exploit_array[i] = output[0].acquisition_function_GP_UCB_marginalised_mean_flux(np.array([parameter_samples[i],]), nu=1., exploitation_weight=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#n_samples = 200\n",
    "parameter_samples2 = histogram_output[0] #np.linspace(output[0].param_limits[2, 0], output[0].param_limits[2, 1], num=n_samples)\n",
    "acquisition_function_exploit_array2 = np.zeros_like(parameter_samples2)\n",
    "for i in range(parameter_samples2.shape[0]):\n",
    "    acquisition_function_exploit_array2[i] = output[0].acquisition_function_GP_UCB_marginalised_mean_flux(np.array([parameter_samples2[i],]), nu=1., exploitation_weight=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(parameter_samples2, np.log(histogram_output[1] / np.max(histogram_output[1])))\n",
    "plt.xlim([0.89, 1.11])\n",
    "plt.ylim([-2.5, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(parameter_samples2, 100*acquisition_function_exploit_array2[:parameter_samples2.shape[0]])\n",
    "plt.axvline(x=0.9, color='black', ls=':')\n",
    "plt.axvline(x=1., color='black', ls=':')\n",
    "plt.axvline(x=1.1, color='black', ls=':')\n",
    "plt.xlim([0.89, 1.11])\n",
    "plt.ylim([0., 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(parameter_samples2, np.log(histogram_output[1] / np.max(histogram_output[1])), label=r'Exploitation term')\n",
    "plt.plot(parameter_samples2, 100*acquisition_function_exploit_array2[:parameter_samples2.shape[0]], label=r'Exploration term')\n",
    "plt.plot(parameter_samples2, np.log(histogram_output[1] / np.max(histogram_output[1])) + 100.*acquisition_function_exploit_array2[:parameter_samples2.shape[0]], label=r'GP-UCB acquisition function')\n",
    "\n",
    "plt.legend(frameon=False)\n",
    "#plt.axvline(x=0.9, color='black', ls=':')\n",
    "plt.axvline(x=0.92, color='blue', ls=':')\n",
    "plt.axvline(x=0.925, color='green', ls=':')\n",
    "#plt.axvline(x=0.95, color='black', ls=':')\n",
    "plt.xlim([0.89, 0.95])\n",
    "plt.ylim([-0.1, 0.2])\n",
    "plt.xlabel(r'heat amp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0].param_limits[0] = np.array([-0.24, 0.24])\n",
    "print(output[0].param_limits)\n",
    "output[0].log_likelihood_marginalised_mean_flux(np.array([0.95,]), integration_method='Monte-Carlo', integration_options=6000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output[0].param_limits[0] = np.array([-0.007, 0.007])\n",
    "#output[0].param_limits[1] = np.array([0.948, 0.952])\n",
    "\n",
    "integration_bounds = [[-0.08, 0.08], [0.936, 0.964]]\n",
    "\n",
    "#mmh.dps = 50\n",
    "integration_instance = mmh.calculus.quadrature.GaussLegendre\n",
    "print(integration_instance)\n",
    "\n",
    "likelihood_marginalised = np.zeros(10)\n",
    "exploration_term = np.zeros_like(likelihood_marginalised)\n",
    "#parameter_samples = np.linspace(output[0].param_limits[2, 0] + 0.01, output[0].param_limits[2, 1], num=likelihood_marginalised.shape[0], endpoint=False)\n",
    "parameter_samples = np.linspace(0.912, 0.928, num=likelihood_marginalised.shape[0])\n",
    "for i in range(likelihood_marginalised.shape[0]):\n",
    "    parameter_vector = np.array([parameter_samples[i],])\n",
    "    #likelihood_marginalised[i] = output[0].log_likelihood_marginalised_mean_flux(np.array([parameter_samples[i],]), integration_method='Quadrature', integration_options=integration_instance)\n",
    "    likelihood_marginalised[i] = output[0].acquisition_function_GP_UCB_marginalised_mean_flux(parameter_vector, nu=0., integration_options='gauss-legendre', integration_bounds=integration_bounds)\n",
    "    exploration_term[i] = output[0].acquisition_function_GP_UCB_marginalised_mean_flux(parameter_vector, exploitation_weight=None, nu=1.e4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(parameter_samples, likelihood_marginalised)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(parameter_samples, likelihood_marginalised - np.nanmax(likelihood_marginalised))\n",
    "plt.scatter(parameter_samples, exploration_term, color='red')\n",
    "plt.plot(histogram_output[0], np.log(histogram_output[1] / np.nanmax(histogram_output[1])), color='blue')\n",
    "plt.axvline(x=0.92)\n",
    "plt.xlim([0.89, 0.95])\n",
    "plt.ylim([-0.2, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(parameter_samples, likelihood_marginalised - np.nanmax(likelihood_marginalised), color='red')\n",
    "#sb.kdeplot(posterior_samples[:, 2])\n",
    "plt.plot(histogram_output[0], np.log(histogram_output[1] / np.nanmax(histogram_output[1])))\n",
    "plt.axvline(x=0.92, color='black')\n",
    "plt.xlim([0.91, 0.93])\n",
    "plt.ylim([-0.01, 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(parameter_samples, np.exp(likelihood_marginalised - np.nanmax(likelihood_marginalised)), color='red')\n",
    "#sb.kdeplot(posterior_samples[:, 2])\n",
    "plt.plot(histogram_output[0], histogram_output[1] / np.nanmax(histogram_output[1]))\n",
    "plt.axvline(x=0.92, color='black')\n",
    "plt.xlim([0.8, 1.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integration_bounds = [[-0.08, 0.08], [0.936, 0.964]]\n",
    "\n",
    "acquisition_optimisation = output[0].optimise_acquisition_function(np.array([1.1,]), optimisation_bounds=[(0.81, 1.19),], nu=0., integration_bounds=integration_bounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acquisition_optimisation.x)\n",
    "print(acquisition_optimisation.success)\n",
    "print(acquisition_optimisation.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_truth = np.array([0., 0.95, 0.975, 2.25e-09, 0.08333333333333326, 0.9166666666666666, 0.6916666666666667])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimisation_bounds = [tuple(output[0].param_limits[i]) for i in range(parameter_truth.shape[0])]\n",
    "print(optimisation_bounds)\n",
    "optimisation_bounds_unit_cube = [(1.e-7, 1. - 1.e-7) for i in range(parameter_truth.shape[0] - 2)]\n",
    "print(optimisation_bounds_unit_cube)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integration_bounds = [[-0.2, 0.2], [0.85, 1.05]]\n",
    "\n",
    "#parameter_truth = parameter_truth * 1.01\n",
    "#print(parameter_truth)\n",
    "#parameter_truth_unit_cube = map_to_unit_cube(parameter_truth, output[0].param_limits)\n",
    "parameter_truth_unit_cube = 1.e-7 + npr.rand(5) * (1. - 2.e-7)\n",
    "print(parameter_truth_unit_cube)\n",
    "\n",
    "def likelihood_function(parameter_vector):\n",
    "    print(parameter_vector, map_from_unit_cube(parameter_vector, output[0].param_limits[2:]))\n",
    "    likelihood_evaluation = -1. * output[0].log_likelihood_marginalised_mean_flux(map_from_unit_cube(parameter_vector, output[0].param_limits[2:]), integration_bounds=integration_bounds)\n",
    "    print(likelihood_evaluation)\n",
    "    return likelihood_evaluation\n",
    "\n",
    "#acquisition_optimisation = spo.minimize(likelihood_function, parameter_truth_unit_cube, bounds=optimisation_bounds_unit_cube, options={'disp': True})\n",
    "acquisition_optimisation = spo.basinhopping(likelihood_function, parameter_truth_unit_cube, minimizer_kwargs={'bounds': optimisation_bounds_unit_cube, 'options': {'disp': True}}, disp=True)\n",
    "\n",
    "print(acquisition_optimisation.x)\n",
    "print(acquisition_optimisation.success)\n",
    "print(acquisition_optimisation.message)\n",
    "\n",
    "print(map_from_unit_cube(acquisition_optimisation.x, output[0].param_limits[2:]))\n",
    "#print(map_from_unit_cube(acquisition_optimisation.x, output[0].param_limits) - parameter_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_instance.close()\n",
    "#pool_instance.join()\n",
    "del pool_instance\n",
    "\n",
    "n_process = 8\n",
    "\n",
    "integration_bounds = [[-0.2, 0.2], [0.85, 1.05]]\n",
    "\n",
    "def likelihood_function(parameter_vector):\n",
    "    #print(parameter_vector, map_from_unit_cube(parameter_vector, output[0].param_limits[2:]))\n",
    "    likelihood_evaluation = -1. * output[0].log_likelihood_marginalised_mean_flux(map_from_unit_cube(parameter_vector, output[0].param_limits[2:]), integration_bounds=integration_bounds)\n",
    "    #print(likelihood_evaluation)\n",
    "    return likelihood_evaluation\n",
    "\n",
    "def optimisation_function(optimisation_arguments):\n",
    "    false_number, parameter_truth_unit_cube = optimisation_arguments\n",
    "\n",
    "    acquisition_optimisation = spo.minimize(likelihood_function, parameter_truth_unit_cube, bounds=optimisation_bounds_unit_cube, options={'disp': False})\n",
    "    #print(acquisition_optimisation.success)\n",
    "    #print(acquisition_optimisation.message)\n",
    "    return acquisition_optimisation.x\n",
    "#acquisition_optimisation = spo.basinhopping(likelihood_function, parameter_truth_unit_cube, minimizer_kwargs={'bounds': optimisation_bounds_unit_cube, 'options': {'disp': True}}, disp=True)\n",
    "\n",
    "optimisation_arguments_list = [(0., 1.e-7 + npr.rand(5) * (1. - 2.e-7)) for i in range(n_process)]\n",
    "print(optimisation_arguments_list)\n",
    "pool_instance = mu.Pool(n_process)\n",
    "optimisation_results = pool_instance.map(optimisation_function, optimisation_arguments_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[-5.86448758e-02  9.64476445e-01  9.88091992e-01  2.40207473e-09\n",
    "  1.30284380e-01  1.06729539e+00  6.91094030e-01]\n",
    "[-6.73717605e-02  9.79216137e-01  9.86009810e-01  2.36946453e-09\n",
    "  1.88449411e-01  9.78980755e-01  6.89627409e-01]\n",
    "[-7.77305181e-03  9.28751149e-01  9.89338079e-01  2.24040312e-09\n",
    " -1.96653971e-02  1.28341469e+00  6.88152784e-01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[9.92761335e-01 2.42336688e-09 3.53231102e-02 1.24026185e+00\n",
    " 6.90070110e-01]\n",
    "[9.98922713e-01 1.78991408e-09 2.00561918e-01 8.91035270e-01\n",
    " 7.16109410e-01]\n",
    "[1.01805673e+00 1.55893077e-09 3.39285232e-01 8.39858390e-01\n",
    " 7.28723550e-01]\n",
    "[ 9.76096007e-01  2.27948154e-09 -2.11387489e-01  1.32066491e+00\n",
    "  6.88386399e-01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize\n",
    "from multiprocessing import Pool\n",
    "#del emcee\n",
    "import scipy\n",
    "import numpy.linalg as npl\n",
    "import corner\n",
    "\n",
    "def square(x):\n",
    "    print(x)\n",
    "    print(np.linalg.pinv(np.eye(2)))\n",
    "    return np.sum(x**2+ 2*x)\n",
    "\n",
    "def minimize(args):\n",
    "    f,x = args\n",
    "    res = optimize.minimize(f, x, method = 'L-BFGS-B')\n",
    "    return res.x\n",
    "\n",
    "x = np.random.rand(8,10)\n",
    "\n",
    "args = [(square,x[i]) for i in range(8)]\n",
    "p = Pool(8)\n",
    "p.map(minimize,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy import optimize\n",
    "#from multiprocessing import Pool\n",
    "#import multiprocessing\n",
    "#multiprocessing.set_start_method('forkserver')\n",
    "\n",
    "n_process = 1\n",
    "n_parameters = 7\n",
    "\n",
    "output[0].random_function = 1.\n",
    "\n",
    "class FunctionClass(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def function_evaluation(self, parameters):\n",
    "        #return np.sum(parameters**2+ 2*parameters)\n",
    "        #return output[0].random_function\n",
    "        print('Evaluating likelihood function')\n",
    "        tau0_factors = mflux.mean_flux_slope_to_factor(output[0].zout, parameters[0])\n",
    "        emulator_output = (output[0].gpemu.kf, output[0].gpemu.nk, output[0].gpemu.nz, output[0].gpemu.coreg)\n",
    "        emulator_output2 = (output[0].gpemu.gps[0].params, output[0].gpemu.gps[0].param_limits, output[0].gpemu.gps[0].intol, output[0].gpemu.gps[0]._test_interp, output[0].gpemu.gps[0].coreg)\n",
    "        emulator_output3 = (output[0].gpemu.gps[0].scalefactors, output[0].gpemu.gps[0].paramzero)\n",
    "        parameters_unit_cube = map_to_unit_cube(parameters[1:], output[0].gpemu.gps[0].param_limits)\n",
    "        #numpy_output = np.linalg.pinv(np.eye(2))\n",
    "        #emulator_output4 = output[0].gpemu.gps[0].gp.optimize(messages=True)\n",
    "        #.predict(parameters_unit_cube.reshape(1, -1))\n",
    "        #emulator_output2 = output[0].gpemu.gps[0].predict(parameters[1:].reshape(1, -1))\n",
    "        #function_predicted, function_std = output[0].gpemu.predict(np.array(parameters[1:]).reshape(1, -1), tau0_factors=tau0_factors)\n",
    "        #full_output = output[0].likelihood(parameters)\n",
    "        print('Finished evaluating likelihood function')\n",
    "        #full_output = output[0].get_BOSS_covariance_single_z(output[0].zout[0])\n",
    "        #full_output = output[0].\n",
    "        #print(full_output)\n",
    "        full_output = 1.\n",
    "        return np.mean(full_output)\n",
    "\n",
    "function_class_instance = FunctionClass()\n",
    "\n",
    "def optimisation_function(parameter_vector):\n",
    "    print('parameter_vector =', parameter_vector)\n",
    "    #eturn np.sum(parameter_vector**2+ 2*parameter_vector)\n",
    "    return function_class_instance.function_evaluation(parameter_vector)\n",
    "    #return output[0].random_function\n",
    "    #return -1. * output[0].likelihood(parameter_vector)\n",
    "    #return -1. * output[0].log_likelihood_marginalised_mean_flux(parameter_vector)\n",
    "\n",
    "def get_prior_limits():\n",
    "    #prior_limits = np.ones((5, 2))\n",
    "    #prior_limits[:, 0] *= -1.5\n",
    "    #prior_limits[:, 1] *= -0.5\n",
    "    #return prior_limits\n",
    "    return output[0].param_limits[7 - n_parameters:]\n",
    "\n",
    "def get_optimisation_function(x):\n",
    "    print('x in get_optimisation_function =', x)\n",
    "    #prior_limits = np.ones((5, 2))\n",
    "    #prior_limits[:, 0] *= -1.5\n",
    "    #prior_limits[:, 1] *= -0.5\n",
    "    prior_limits = get_prior_limits()\n",
    "    x_unscaled = map_from_unit_cube(x, prior_limits)\n",
    "    print('x_unscaled in get_optimisation_function =', x_unscaled)\n",
    "    return optimisation_function(x_unscaled)\n",
    "    #return np.sum(x_unscaled**2+ 2*x_unscaled)\n",
    "    #return output[0].log_likelihood_marginalised_mean_flux(x_unscaled)\n",
    "\n",
    "def minimize(args):\n",
    "    x_bounds = [[1.e-7, 1. - 1.e-7] for i in range(n_parameters)] #For unit hypercube\n",
    "    f, x = args\n",
    "    res = spo.minimize(f, x, method = 'L-BFGS-B', bounds=x_bounds, options={'disp': True})\n",
    "    return res.x\n",
    "\n",
    "x = 1.e-7 + np.random.rand(n_process, n_parameters) * (1. - 2.e-7) #Starting positions\n",
    "print('x (starting positions) =', x)\n",
    "\n",
    "args = [(get_optimisation_function, x[i]) for i in range(n_process)]\n",
    "p = mu.Pool(n_process)\n",
    "optimisation_result = p.map(minimize, args)\n",
    "#optimisation_result = list(map(minimize, args)) #p.\n",
    "print('optimisation_result =', optimisation_result)\n",
    "\n",
    "optimisation_result_rescaled = [map_from_unit_cube(optimisation_result[i], get_prior_limits()) for i in range(n_process)]\n",
    "print('optimisation_result_rescaled =', optimisation_result_rescaled)\n",
    "print(np.array(optimisation_result) - np.array(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(minimize, args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0].gpemu.gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
