{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run /home/keir/Software/lya_emulator/main.py /share/hypatia/sbird/Lya_Boss /home/keir/Plots/Emulator hires_s8_new /home/keir/Data/emulator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/apps/anaconda/python3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5)\n",
      "Beginning to initialise LikelihoodClass at 2018-11-08 15:57:20.561888\n",
      "Looking for spectra in /home/keir/Data/emulator/hot_cold_test/HeliumHeatAmp0.92/output\n",
      "Found spectra in None\n",
      "Found spectra in None\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b821483cc50>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b8164350e48>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b8215950a20>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b8215950898>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b8215950cc0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b82159581d0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b8215958320>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b8215958f98>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b82159644e0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b8215964358>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b8215964400>\n",
      "Looking for spectra in /home/keir/Data/emulator/hot_cold/HeliumHeatAmp0.9/output\n",
      "Found spectra in None\n",
      "Found spectra in None\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b8215970940>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b8215970128>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b82159703c8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b8215970b70>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b83fabb70b8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b83fabb75c0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b83fabb7908>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b83fabb7cc0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b83fabc01d0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b83fabc02b0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b83fabc0710>\n",
      "Looking for spectra in /home/keir/Data/emulator/hot_cold/HeliumHeatAmp1/output\n",
      "Found spectra in None\n",
      "Found spectra in None\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b83fabcca58>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b83fabcc518>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b83fabcc3c8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b83fabccc88>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b83fabcc860>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b83fabd0198>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b83fabd0160>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b83fabd0dd8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b83fabdc320>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b83fabdc3c8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b83fabdcb38>\n",
      "Looking for spectra in /home/keir/Data/emulator/hot_cold/HeliumHeatAmp1.1/output\n",
      "Found spectra in None\n",
      "Found spectra in None\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b83fabe7b70>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b83fabe7630>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b83fabe7080>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b83fabe7da0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b83fabec390>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b83fabec2b0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b83fabec278>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b83fabf9438>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b83fabf93c8>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b83fabf94e0>\n",
      "Found spectra in <fake_spectra.spectra.Spectra object at 0x2b83fabf9c50>\n",
      "Number of redshifts for emulator generation = 11\n",
      "  \u001b[1mlinear.  \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mvariances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1msum.            \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mlinear.variances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.variance    \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.lengthscale \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i      f              |g|        \n",
      "    00s03  0007  -6.144187e+03   2.516794e+02 \n",
      "    00s06  0017  -6.158131e+03   1.421471e-01 \n",
      "    00s10  0028  -6.158216e+03   2.601426e-03 \n",
      "    00s13  0040  -6.158218e+03   8.997740e-06 \n",
      "    00s14  0042  -6.158218e+03   9.036379e-06 \n",
      "Runtime:     00s14\n",
      "Optimization status: Converged\n",
      "\n",
      "\n",
      "Name : GP regression\n",
      "Objective : -6158.2182681676095\n",
      "Number of Parameters : 4\n",
      "Number of Optimization Parameters : 4\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mGP_regression.         \u001b[0;0m  |                  value  |  constraints  |  priors\n",
      "  \u001b[1msum.linear.variances   \u001b[0;0m  |     0.8903557376333252  |      +ve      |        \n",
      "  \u001b[1msum.rbf.variance       \u001b[0;0m  |     5.7313823675725075  |      +ve      |        \n",
      "  \u001b[1msum.rbf.lengthscale    \u001b[0;0m  |     2.9325828818839876  |      +ve      |        \n",
      "  \u001b[1mGaussian_noise.variance\u001b[0;0m  |  7.942210942131448e-16  |      +ve      |        \n",
      "  \u001b[1mlinear.  \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mvariances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1msum.            \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mlinear.variances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.variance    \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.lengthscale \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i      f              |g|        \n",
      "    00s01  0005  -6.232733e+03   2.056980e+02 \n",
      "    00s04  0016  -6.322021e+03   7.897046e+01 \n",
      "    00s07  0025  -6.335954e+03   9.522484e-01 \n",
      "    00s11  0037  -6.335962e+03   6.511312e-06 \n",
      "    00s21  0068  -6.335962e+03   6.451781e-06 \n",
      "Runtime:     00s21\n",
      "Optimization status: Errorb'ABNORMAL_TERMINATION_IN_LNSRCH'\n",
      "\n",
      "\n",
      "Name : GP regression\n",
      "Objective : -6335.961557692317\n",
      "Number of Parameters : 4\n",
      "Number of Optimization Parameters : 4\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mGP_regression.         \u001b[0;0m  |                 value  |  constraints  |  priors\n",
      "  \u001b[1msum.linear.variances   \u001b[0;0m  |    1.7483151336853118  |      +ve      |        \n",
      "  \u001b[1msum.rbf.variance       \u001b[0;0m  |    35.207948348946836  |      +ve      |        \n",
      "  \u001b[1msum.rbf.lengthscale    \u001b[0;0m  |     6.148582308598688  |      +ve      |        \n",
      "  \u001b[1mGaussian_noise.variance\u001b[0;0m  |  9.99368412652809e-15  |      +ve      |        \n",
      "  \u001b[1mlinear.  \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mvariances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1msum.            \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mlinear.variances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.variance    \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.lengthscale \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i      f              |g|        \n",
      "    00s01  0005  -6.317798e+03   3.947949e+02 \n",
      "    00s05  0017  -6.449670e+03   1.051937e+02 \n",
      "    00s08  0027  -6.461510e+03   3.174814e-02 \n",
      "    00s13  0043  -6.461532e+03   1.226374e-03 \n",
      "    00s20  0064  -6.461532e+03   3.367770e-05 \n",
      "Runtime:     00s20\n",
      "Optimization status: Converged\n",
      "\n",
      "\n",
      "Name : GP regression\n",
      "Objective : -6461.532439408553\n",
      "Number of Parameters : 4\n",
      "Number of Optimization Parameters : 4\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mGP_regression.         \u001b[0;0m  |                  value  |  constraints  |  priors\n",
      "  \u001b[1msum.linear.variances   \u001b[0;0m  |     1.1675180008717132  |      +ve      |        \n",
      "  \u001b[1msum.rbf.variance       \u001b[0;0m  |     20.052443586056008  |      +ve      |        \n",
      "  \u001b[1msum.rbf.lengthscale    \u001b[0;0m  |       6.17339332717424  |      +ve      |        \n",
      "  \u001b[1mGaussian_noise.variance\u001b[0;0m  |  1.892760379455966e-15  |      +ve      |        \n",
      "  \u001b[1mlinear.  \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mvariances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1msum.            \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mlinear.variances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.variance    \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.lengthscale \u001b[0;0m  |    1.0  |      +ve      |        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i      f              |g|        \n",
      "    00s02  0008  -6.456869e+03   2.790725e+03 \n",
      "    00s05  0018  -6.555903e+03   1.704395e+00 \n",
      "    00s06  0024  -6.556016e+03   4.163063e-05 \n",
      "    00s09  0032  -6.556021e+03   1.646643e-04 \n",
      "    00s09  0034  -6.556021e+03   4.163863e-06 \n",
      "Runtime:     00s09\n",
      "Optimization status: Converged\n",
      "\n",
      "\n",
      "Name : GP regression\n",
      "Objective : -6556.021100338643\n",
      "Number of Parameters : 4\n",
      "Number of Optimization Parameters : 4\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mGP_regression.         \u001b[0;0m  |                   value  |  constraints  |  priors\n",
      "  \u001b[1msum.linear.variances   \u001b[0;0m  |      0.7877116042498885  |      +ve      |        \n",
      "  \u001b[1msum.rbf.variance       \u001b[0;0m  |       15.33874679043499  |      +ve      |        \n",
      "  \u001b[1msum.rbf.lengthscale    \u001b[0;0m  |       6.501977508061914  |      +ve      |        \n",
      "  \u001b[1mGaussian_noise.variance\u001b[0;0m  |  1.3769862544832567e-15  |      +ve      |        \n",
      "  \u001b[1mlinear.  \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mvariances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1msum.            \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mlinear.variances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.variance    \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.lengthscale \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i      f              |g|        \n",
      "    00s01  0004  -6.460804e+03   1.141960e+04 \n",
      "    00s03  0013  -6.627639e+03   7.776703e+01 \n",
      "    00s06  0021  -6.633334e+03   3.599351e-01 \n",
      "    00s06  0022  -6.633348e+03   3.018706e-02 \n",
      "    00s15  0045  -6.633348e+03   5.211171e-05 \n",
      "Runtime:     00s15\n",
      "Optimization status: Converged\n",
      "\n",
      "\n",
      "Name : GP regression\n",
      "Objective : -6633.348222934401\n",
      "Number of Parameters : 4\n",
      "Number of Optimization Parameters : 4\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mGP_regression.         \u001b[0;0m  |                  value  |  constraints  |  priors\n",
      "  \u001b[1msum.linear.variances   \u001b[0;0m  |     0.5321891092971343  |      +ve      |        \n",
      "  \u001b[1msum.rbf.variance       \u001b[0;0m  |     14.456874906790887  |      +ve      |        \n",
      "  \u001b[1msum.rbf.lengthscale    \u001b[0;0m  |      7.039381155239546  |      +ve      |        \n",
      "  \u001b[1mGaussian_noise.variance\u001b[0;0m  |  8.790404031664155e-14  |      +ve      |        \n",
      "  \u001b[1mlinear.  \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mvariances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1msum.            \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mlinear.variances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.variance    \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.lengthscale \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i      f              |g|        \n",
      "    00s01  0005  -6.589800e+03   2.702218e+04 \n",
      "    00s05  0017  -6.684586e+03   9.411012e+00 \n",
      "    00s05  0020  -6.685443e+03   2.523362e-01 \n",
      "    00s07  0024  -6.685451e+03   3.361747e-05 \n",
      "    00s09  0030  -6.685451e+03   4.274869e-04 \n",
      "Runtime:     00s09\n",
      "Optimization status: Converged\n",
      "\n",
      "\n",
      "Name : GP regression\n",
      "Objective : -6685.451117471615\n",
      "Number of Parameters : 4\n",
      "Number of Optimization Parameters : 4\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mGP_regression.         \u001b[0;0m  |                   value  |  constraints  |  priors\n",
      "  \u001b[1msum.linear.variances   \u001b[0;0m  |      0.3639962699071603  |      +ve      |        \n",
      "  \u001b[1msum.rbf.variance       \u001b[0;0m  |       11.05265636768623  |      +ve      |        \n",
      "  \u001b[1msum.rbf.lengthscale    \u001b[0;0m  |       6.991419988640297  |      +ve      |        \n",
      "  \u001b[1mGaussian_noise.variance\u001b[0;0m  |  1.3282385843067225e-13  |      +ve      |        \n",
      "  \u001b[1mlinear.  \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mvariances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1msum.            \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mlinear.variances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.variance    \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.lengthscale \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i      f              |g|        \n",
      "    00s01  0005  -6.592328e+03   5.510745e+04 \n",
      "    00s05  0016  -6.706137e+03   2.478830e+01 \n",
      "    00s07  0021  -6.707764e+03   1.518407e-01 \n",
      "    00s07  0023  -6.707768e+03   7.742041e-04 \n",
      "    00s15  0050  -6.707768e+03   4.483725e-04 \n",
      "Runtime:     00s15\n",
      "Optimization status: Converged\n",
      "\n",
      "\n",
      "Name : GP regression\n",
      "Objective : -6707.768266567769\n",
      "Number of Parameters : 4\n",
      "Number of Optimization Parameters : 4\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mGP_regression.         \u001b[0;0m  |                  value  |  constraints  |  priors\n",
      "  \u001b[1msum.linear.variances   \u001b[0;0m  |     0.1888889110406054  |      +ve      |        \n",
      "  \u001b[1msum.rbf.variance       \u001b[0;0m  |     10.676626845890112  |      +ve      |        \n",
      "  \u001b[1msum.rbf.lengthscale    \u001b[0;0m  |     7.0493200280355985  |      +ve      |        \n",
      "  \u001b[1mGaussian_noise.variance\u001b[0;0m  |  1.677116755803194e-13  |      +ve      |        \n",
      "  \u001b[1mlinear.  \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mvariances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1msum.            \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mlinear.variances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.variance    \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.lengthscale \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i      f              |g|        \n",
      "    00s00  0001  -5.397691e+03   1.227353e+06 \n",
      "    00s02  0007  -6.621785e+03   3.714489e+04 \n",
      "    00s06  0022  -6.721123e+03   3.474689e-01 \n",
      "    00s07  0024  -6.721190e+03   4.403165e-01 \n",
      "    00s11  0028  -6.721202e+03   1.166092e-05 \n",
      "    00s23  0066  -6.721202e+03   7.735776e-07 \n",
      "Runtime:     00s23\n",
      "Optimization status: Converged\n",
      "\n",
      "\n",
      "Name : GP regression\n",
      "Objective : -6721.201955403356\n",
      "Number of Parameters : 4\n",
      "Number of Optimization Parameters : 4\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mGP_regression.         \u001b[0;0m  |                   value  |  constraints  |  priors\n",
      "  \u001b[1msum.linear.variances   \u001b[0;0m  |    0.021723708771497922  |      +ve      |        \n",
      "  \u001b[1msum.rbf.variance       \u001b[0;0m  |       16.59679910358226  |      +ve      |        \n",
      "  \u001b[1msum.rbf.lengthscale    \u001b[0;0m  |       7.751319139213525  |      +ve      |        \n",
      "  \u001b[1mGaussian_noise.variance\u001b[0;0m  |  1.3248685709835453e-14  |      +ve      |        \n",
      "  \u001b[1mlinear.  \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mvariances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1msum.            \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mlinear.variances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.variance    \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.lengthscale \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i      f              |g|        \n",
      "    00s03  0010  -6.680182e+03   8.983560e+02 \n",
      "    00s08  0026  -6.730363e+03   1.409796e+00 \n",
      "    00s10  0033  -6.730501e+03   1.418899e-02 \n",
      "    00s12  0040  -6.730503e+03   2.433969e-04 \n",
      "Runtime:     00s12\n",
      "Optimization status: Converged\n",
      "\n",
      "\n",
      "Name : GP regression\n",
      "Objective : -6730.503472417287\n",
      "Number of Parameters : 4\n",
      "Number of Optimization Parameters : 4\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mGP_regression.         \u001b[0;0m  |                   value  |  constraints  |  priors\n",
      "  \u001b[1msum.linear.variances   \u001b[0;0m  |  1.0201366603880804e-06  |      +ve      |        \n",
      "  \u001b[1msum.rbf.variance       \u001b[0;0m  |      12.655768757959782  |      +ve      |        \n",
      "  \u001b[1msum.rbf.lengthscale    \u001b[0;0m  |      7.2292838036535665  |      +ve      |        \n",
      "  \u001b[1mGaussian_noise.variance\u001b[0;0m  |    9.37531043724785e-16  |      +ve      |        \n",
      "  \u001b[1mlinear.  \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mvariances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1msum.            \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mlinear.variances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.variance    \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.lengthscale \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i      f              |g|        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    00s02  0004  -6.590515e+03   1.692305e+04 \n",
      "    00s04  0013  -6.676206e+03   6.908817e+01 \n",
      "    00s09  0029  -6.684458e+03   5.629157e+00 \n",
      "    00s12  0039  -6.684549e+03   1.975730e-03 \n",
      "    00s14  0045  -6.684560e+03   5.267484e-03 \n",
      "    00s16  0050  -6.684563e+03   1.753054e-03 \n",
      "    00s20  0066  -6.684563e+03   6.483562e-04 \n",
      "Runtime:     00s20\n",
      "Optimization status: Converged\n",
      "\n",
      "\n",
      "Name : GP regression\n",
      "Objective : -6684.562915770979\n",
      "Number of Parameters : 4\n",
      "Number of Optimization Parameters : 4\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mGP_regression.         \u001b[0;0m  |                  value  |  constraints  |  priors\n",
      "  \u001b[1msum.linear.variances   \u001b[0;0m  |  2.992638859825967e-05  |      +ve      |        \n",
      "  \u001b[1msum.rbf.variance       \u001b[0;0m  |     11.166021230859073  |      +ve      |        \n",
      "  \u001b[1msum.rbf.lengthscale    \u001b[0;0m  |      6.664684054764421  |      +ve      |        \n",
      "  \u001b[1mGaussian_noise.variance\u001b[0;0m  |  3.497583848405587e-14  |      +ve      |        \n",
      "  \u001b[1mlinear.  \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mvariances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1msum.            \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mlinear.variances\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.variance    \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mrbf.lengthscale \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i      f              |g|        \n",
      "    00s01  0004  -6.586824e+03   1.619948e+04 \n",
      "    00s04  0014  -6.668322e+03   4.932265e+01 \n",
      "    00s07  0025  -6.673531e+03   6.741723e-01 \n",
      "    00s11  0038  -6.673593e+03   6.228317e-02 \n",
      "    00s14  0046  -6.673595e+03   1.600361e-04 \n",
      "    00s15  0050  -6.673595e+03   1.117114e-04 \n",
      "    00s22  0072  -6.673595e+03   8.575275e-07 \n",
      "Runtime:     00s22\n",
      "Optimization status: Converged\n",
      "\n",
      "\n",
      "Name : GP regression\n",
      "Objective : -6673.595391944331\n",
      "Number of Parameters : 4\n",
      "Number of Optimization Parameters : 4\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mGP_regression.         \u001b[0;0m  |                   value  |  constraints  |  priors\n",
      "  \u001b[1msum.linear.variances   \u001b[0;0m  |     0.08176361845271256  |      +ve      |        \n",
      "  \u001b[1msum.rbf.variance       \u001b[0;0m  |        5.03689893517499  |      +ve      |        \n",
      "  \u001b[1msum.rbf.lengthscale    \u001b[0;0m  |       5.535199310294628  |      +ve      |        \n",
      "  \u001b[1mGaussian_noise.variance\u001b[0;0m  |  3.6676270093668967e-16  |      +ve      |        \n"
     ]
    }
   ],
   "source": [
    "run /home/keir/Software/lya_emulator/main.py /home/keir/Data/emulator /home/keir/Plots/Emulator hot_cold_validation /home/keir/Data/emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import multiprocessing as mu\n",
    "#import corner as co\n",
    "#import seaborn as sb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = np.loadtxt('/home/keir/Data/emulator/AA0.97BB1.3_chain_hot_cold_training3_rescale_2000.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0].add_to_emulator_training_set(np.array([[0.95],]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.50998417 -0.50998417 -0.50586145 ... -0.48512813 -0.48589932\n",
      "  -0.48658443]\n",
      " [-0.50921718 -0.50921718 -0.50523002 ... -0.48886051 -0.48989252\n",
      "  -0.49080934]\n",
      " [-0.5085669  -0.5085669  -0.50468146 ... -0.49240162 -0.49364732\n",
      "  -0.49475398]\n",
      " ...\n",
      " [ 0.49162935  0.49162935  0.49145248 ...  0.53838819  0.54404509\n",
      "   0.54907056]\n",
      " [ 0.49498576  0.49498576  0.4943311  ...  0.5298359   0.53488289\n",
      "   0.53936652]\n",
      " [ 0.49799549  0.49799549  0.49690477 ...  0.52171195  0.5262229\n",
      "   0.53023033]]\n",
      "(30, 35)\n",
      "[[-0.50998417 -0.50998417 -0.50586145 ... -0.48512813 -0.48589932\n",
      "  -0.48658443]\n",
      " [-0.50921718 -0.50921718 -0.50523002 ... -0.48886051 -0.48989252\n",
      "  -0.49080934]\n",
      " [-0.5085669  -0.5085669  -0.50468146 ... -0.49240162 -0.49364732\n",
      "  -0.49475398]\n",
      " ...\n",
      " [ 0.2353587   0.2353587   0.23492179 ...  0.25536494  0.25786303\n",
      "   0.26008228]\n",
      " [ 0.36186514  0.36186514  0.36130745 ...  0.39042633  0.39421921\n",
      "   0.39758873]\n",
      " [ 0.49338109  0.49338109  0.49295972 ...  0.5340979   0.53944209\n",
      "   0.54418975]]\n",
      "(40, 35)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "use_updated_training_set = False\n",
    "GP_predict = output[0].gpemu.predict(np.array([[0.95, 1.15],]), tau0_factors=mflux.mean_flux_slope_to_factor(output[0].zout, 0.), use_updated_training_set=use_updated_training_set)\n",
    "\n",
    "GP_predict2 = output[0].gpemu.predict(np.array([[0.95, 1.15],]), tau0_factors=mflux.mean_flux_slope_to_factor(output[0].zout, 0.), use_updated_training_set=True)\n",
    "\n",
    "#print(GP_predict[0] - GP_predict2[0])\n",
    "print(output[0].gpemu.gps[0].gp.Y)\n",
    "print(output[0].gpemu.gps[0].gp.Y.shape)\n",
    "\n",
    "print(output[0].gpemu.gps[0].gp_updated.Y)\n",
    "print(output[0].gpemu.gps[0].gp_updated.Y.shape)\n",
    "\n",
    "print(np.sum(output[0].gpemu.gps[0].gp_updated.Y[:30] - output[0].gpemu.gps[0].gp.Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.031410723005082e-10\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b82178f8f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(output[0].kf, GP_predict[0][0, :35] * output[0].kf / np.pi, color='red')\n",
    "plt.plot(output[0].kf, GP_predict2[0][0, :35] * output[0].kf / np.pi, color='blue')\n",
    "plt.yscale('log')\n",
    "\n",
    "print(np.max(np.abs((GP_predict[0][0, :] - GP_predict2[0][0, :]) / GP_predict[0][0, :])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_process = 55\n",
    "n_parameters = 3\n",
    "n_marginalised_parameters = 2\n",
    "\n",
    "#optimisation_bounds_unscaled = np.array([[0.81, 1.], [1.3e-9, 2.9e-9], [-0.44, 0.44], [0.56, 1.4], [0.61, 0.79]]) #Convex hull_0\n",
    "#optimisation_bounds_unscaled = np.array([[0.825, 1.], [1.4e-9, 2.8e-9], [-0.385, 0.385], [0.615, 1.35], [0.62, 0.78]]) #Convex hull_1\n",
    "#optimisation_bounds_unscaled = np.array([[0.84, 1.], [1.5e-9, 2.7e-9], [-0.33, 0.33], [0.67, 1.3], [0.63, 0.77]]) #Convex hull_2\n",
    "#optimisation_bounds_unscaled = np.array([[0.915, 0.985], [1.5e-9, 2.5e-9], [-0.2, 0.2], [0.8, 1.3], [0.65, 0.73]]) #Edge\n",
    "#optimisation_bounds_unscaled = np.array([[0.93, 0.98], [1.5e-9, 2.5e-9], [-0.2, 0.2], [0.9, 1.3], [0.655, 0.725]]) #4s\n",
    "\n",
    "#refinement_big\n",
    "optimisation_bounds_unscaled = np.array([[0.9, 1.1],]) #CH2\n",
    "print(optimisation_bounds_unscaled)\n",
    "\n",
    "optimisation_bounds_array = np.zeros_like(optimisation_bounds_unscaled)\n",
    "optimisation_bounds_array[:, 0] = map_to_unit_cube(optimisation_bounds_unscaled[:, 0], output[0].param_limits[n_marginalised_parameters:])\n",
    "optimisation_bounds_array[:, 1] = map_to_unit_cube(optimisation_bounds_unscaled[:, 1], output[0].param_limits[n_marginalised_parameters:])\n",
    "\n",
    "#optimisation_bounds_array = np.ones((n_parameters - n_marginalised_parameters, 2))\n",
    "#optimisation_bounds_array[:, 0] *= 1.e-7\n",
    "#optimisation_bounds_array[:, 1] *= 1. - 1.e-7\n",
    "\n",
    "print(optimisation_bounds_array)\n",
    "optimisation_bounds = [tuple(optimisation_bounds_array[i]) for i in range(n_parameters - n_marginalised_parameters)]\n",
    "print(optimisation_bounds)\n",
    "\n",
    "starting_positions = np.array([npr.uniform(low=optimisation_bounds_array[:, 0], high=optimisation_bounds_array[:, 1]) for i in range(n_process)])\n",
    "#print(starting_positions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mg\n",
    "mg.set_start_method('forkserver', force=True)\n",
    "\n",
    "import acquisition as ac\n",
    "\n",
    "use_updated_training_set = True\n",
    "\n",
    "#starting_positions = 1.e-7 + npr.rand(n_process, n_parameters - n_marginalised_parameters) * (1. - 2.e-7)\n",
    "#optimisation_bounds = [(1.e-7, 1. - 1.e-7) for i in range(n_parameters - n_marginalised_parameters)]\n",
    "#integration_bounds = [list(output[0].param_limits[0]), list(output[0].param_limits[1])]\n",
    "#integration_bounds = [[-0.05, 0.1], [0.92, 1.02]]\n",
    "#integration_bounds = [[-0.04, 0.1], [0.96, 1.02]]\n",
    "integration_bounds = [[-0.04, 0.04], [0.94, 0.96]]\n",
    "argument_list = [(starting_positions[i], output[0], optimisation_bounds, 1., None, integration_bounds, use_updated_training_set) for i in range(n_process)]\n",
    "\n",
    "pool_instance = mg.Pool(n_process)\n",
    "optimisation_output = pool_instance.map(ac.optimise_acquisition_function_parallel, argument_list)\n",
    "\n",
    "[print(map_from_unit_cube(optimisation_output[i].x, output[0].param_limits[n_marginalised_parameters:])) for i in range(n_process)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[print(optimisation_output[i].fun) for i in range(n_process)]\n",
    "\n",
    "[print(map_from_unit_cube(starting_positions[i], output[0].param_limits[n_marginalised_parameters:])) for i in range(n_process)]\n",
    "\n",
    "best_process = np.argmin(np.array([optimisation_output[i].fun for i in range(n_process)]))\n",
    "print(best_process, map_from_unit_cube(optimisation_output[best_process].x, output[0].param_limits[n_marginalised_parameters:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import corner as co\n",
    "\n",
    "corner_plot_labels = [r'$d\\tau_0$', r'$\\tau_0$', r'$n_s$', r'$A_s$', 'heat slope', 'heat amp', 'hub']\n",
    "\n",
    "co.corner(posterior_samples[:, n_marginalised_parameters:], labels=corner_plot_labels[n_marginalised_parameters:], truths=np.concatenate(([], map_from_unit_cube(optimisation_output[best_process].x, output[0].param_limits[n_marginalised_parameters:]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0].param_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisition_function_tau0_amp = output.make_grid_acquisition_function(1, 2, samples=30000, nu=1., exploitation_weight=0.)\n",
    "acquisition_function_tau0_amp[acquisition_function_tau0_amp == 0.] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisition_function_tau0_amp_exploit = output.make_grid_acquisition_function(0, 2, samples=1000, nu=0., exploitation_weight=1.)\n",
    "acquisition_function_tau0_amp_exploit[acquisition_function_tau0_amp_exploit == 0.] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contour(np.log10(acquisition_function_tau0_amp).T, 100, extent=[0.75, 1.25, 0.8, 1.2], origin='image')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.exp(acquisition_function_tau0_amp).T, extent=[-0.25, 0.25, 0.8, 1.2])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 18))\n",
    "plt.imshow(np.exp(acquisition_function_tau0_amp_exploit - np.nanmax(acquisition_function_tau0_amp_exploit)).T, extent=[-0.25, 0.25, 0.8, 1.2])\n",
    "plt.colorbar()\n",
    "#plt.scatter(0.95, 0.95, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisition_function_exploit = output.acquisition_function_GP_UCB_marginalised_mean_flux(np.array([0.95,]), nu=1., exploitation_weight=0.)\n",
    "acquisition_function_exploit = output.acquisition_function_GP_UCB_marginalised_mean_flux(np.array([0.9,]), nu=1., exploitation_weight=0.)\n",
    "acquisition_function_exploit = output.acquisition_function_GP_UCB_marginalised_mean_flux(np.array([1.,]), nu=1., exploitation_weight=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisition_function_exploit = output.acquisition_function_GP_UCB_marginalised_mean_flux(np.array([0.95,]), nu=1., exploitation_weight=1.)\n",
    "acquisition_function_exploit = output.acquisition_function_GP_UCB_marginalised_mean_flux(np.array([0.95,]), nu=0., exploitation_weight=1.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output[0].acquisition_function_GP_UCB_marginalised_mean_flux(np.array([0.81,]), nu=1., exploitation_weight=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(output[0]._get_emulator_error_averaged_mean_flux(np.array([0.81,]))))\n",
    "\n",
    "_ = output[0].likelihood(np.array([0., 0.95, 0.81]))\n",
    "print(np.mean(output[0].emulated_flux_power_std[0]))\n",
    "\n",
    "print(np.mean(output[0].emulated_flux_power_std[0]) / np.mean(output[0].emulated_flux_power[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.cur_results.flatchain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.cur_results.get_lnprob(np.array([0., 0.95, 0.95]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(posterior_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_output = sb.kdeplot(posterior_samples[:, 2]).get_lines()[0].get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_output = plt.hist(posterior_samples[:, 2], bins='auto', normed=True, histtype='step', log=True)\n",
    "print(histogram_output)\n",
    "plt.axvline(x=0.92)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(histogram_output[0].shape)\n",
    "print(histogram_output[1].shape)\n",
    "print(histogram_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#n_samples = 200\n",
    "parameter_samples = (histogram_output[1][:-1] + histogram_output[1][1:]) / 2. #np.linspace(output[0].param_limits[2, 0], output[0].param_limits[2, 1], num=n_samples)\n",
    "acquisition_function_exploit_array = np.zeros_like(parameter_samples)\n",
    "for i in range(parameter_samples.shape[0]):\n",
    "    acquisition_function_exploit_array[i] = output[0].acquisition_function_GP_UCB_marginalised_mean_flux(np.array([parameter_samples[i],]), nu=1., exploitation_weight=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#n_samples = 200\n",
    "parameter_samples2 = histogram_output[0] #np.linspace(output[0].param_limits[2, 0], output[0].param_limits[2, 1], num=n_samples)\n",
    "acquisition_function_exploit_array2 = np.zeros_like(parameter_samples2)\n",
    "for i in range(parameter_samples2.shape[0]):\n",
    "    acquisition_function_exploit_array2[i] = output[0].acquisition_function_GP_UCB_marginalised_mean_flux(np.array([parameter_samples2[i],]), nu=1., exploitation_weight=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(parameter_samples2, np.log(histogram_output[1] / np.max(histogram_output[1])))\n",
    "plt.xlim([0.89, 1.11])\n",
    "plt.ylim([-2.5, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(parameter_samples2, 100*acquisition_function_exploit_array2[:parameter_samples2.shape[0]])\n",
    "plt.axvline(x=0.9, color='black', ls=':')\n",
    "plt.axvline(x=1., color='black', ls=':')\n",
    "plt.axvline(x=1.1, color='black', ls=':')\n",
    "plt.xlim([0.89, 1.11])\n",
    "plt.ylim([0., 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(parameter_samples2, np.log(histogram_output[1] / np.max(histogram_output[1])), label=r'Exploitation term')\n",
    "plt.plot(parameter_samples2, 100*acquisition_function_exploit_array2[:parameter_samples2.shape[0]], label=r'Exploration term')\n",
    "plt.plot(parameter_samples2, np.log(histogram_output[1] / np.max(histogram_output[1])) + 100.*acquisition_function_exploit_array2[:parameter_samples2.shape[0]], label=r'GP-UCB acquisition function')\n",
    "\n",
    "plt.legend(frameon=False)\n",
    "#plt.axvline(x=0.9, color='black', ls=':')\n",
    "plt.axvline(x=0.92, color='blue', ls=':')\n",
    "plt.axvline(x=0.925, color='green', ls=':')\n",
    "#plt.axvline(x=0.95, color='black', ls=':')\n",
    "plt.xlim([0.89, 0.95])\n",
    "plt.ylim([-0.1, 0.2])\n",
    "plt.xlabel(r'heat amp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0].param_limits[0] = np.array([-0.24, 0.24])\n",
    "print(output[0].param_limits)\n",
    "output[0].log_likelihood_marginalised_mean_flux(np.array([0.95,]), integration_method='Monte-Carlo', integration_options=6000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output[0].param_limits[0] = np.array([-0.007, 0.007])\n",
    "#output[0].param_limits[1] = np.array([0.948, 0.952])\n",
    "\n",
    "integration_bounds = [[-0.08, 0.08], [0.936, 0.964]]\n",
    "\n",
    "#mmh.dps = 50\n",
    "integration_instance = mmh.calculus.quadrature.GaussLegendre\n",
    "print(integration_instance)\n",
    "\n",
    "likelihood_marginalised = np.zeros(10)\n",
    "exploration_term = np.zeros_like(likelihood_marginalised)\n",
    "#parameter_samples = np.linspace(output[0].param_limits[2, 0] + 0.01, output[0].param_limits[2, 1], num=likelihood_marginalised.shape[0], endpoint=False)\n",
    "parameter_samples = np.linspace(0.912, 0.928, num=likelihood_marginalised.shape[0])\n",
    "for i in range(likelihood_marginalised.shape[0]):\n",
    "    parameter_vector = np.array([parameter_samples[i],])\n",
    "    #likelihood_marginalised[i] = output[0].log_likelihood_marginalised_mean_flux(np.array([parameter_samples[i],]), integration_method='Quadrature', integration_options=integration_instance)\n",
    "    likelihood_marginalised[i] = output[0].acquisition_function_GP_UCB_marginalised_mean_flux(parameter_vector, nu=0., integration_options='gauss-legendre', integration_bounds=integration_bounds)\n",
    "    exploration_term[i] = output[0].acquisition_function_GP_UCB_marginalised_mean_flux(parameter_vector, exploitation_weight=None, nu=1.e4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(parameter_samples, likelihood_marginalised)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(parameter_samples, likelihood_marginalised - np.nanmax(likelihood_marginalised))\n",
    "plt.scatter(parameter_samples, exploration_term, color='red')\n",
    "plt.plot(histogram_output[0], np.log(histogram_output[1] / np.nanmax(histogram_output[1])), color='blue')\n",
    "plt.axvline(x=0.92)\n",
    "plt.xlim([0.89, 0.95])\n",
    "plt.ylim([-0.2, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(parameter_samples, likelihood_marginalised - np.nanmax(likelihood_marginalised), color='red')\n",
    "#sb.kdeplot(posterior_samples[:, 2])\n",
    "plt.plot(histogram_output[0], np.log(histogram_output[1] / np.nanmax(histogram_output[1])))\n",
    "plt.axvline(x=0.92, color='black')\n",
    "plt.xlim([0.91, 0.93])\n",
    "plt.ylim([-0.01, 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(parameter_samples, np.exp(likelihood_marginalised - np.nanmax(likelihood_marginalised)), color='red')\n",
    "#sb.kdeplot(posterior_samples[:, 2])\n",
    "plt.plot(histogram_output[0], histogram_output[1] / np.nanmax(histogram_output[1]))\n",
    "plt.axvline(x=0.92, color='black')\n",
    "plt.xlim([0.8, 1.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integration_bounds = [[-0.08, 0.08], [0.936, 0.964]]\n",
    "\n",
    "acquisition_optimisation = output[0].optimise_acquisition_function(np.array([1.1,]), optimisation_bounds=[(0.81, 1.19),], nu=0., integration_bounds=integration_bounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acquisition_optimisation.x)\n",
    "print(acquisition_optimisation.success)\n",
    "print(acquisition_optimisation.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_truth = np.array([0., 0.95, 0.975, 2.25e-09, 0.08333333333333326, 0.9166666666666666, 0.6916666666666667])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimisation_bounds = [tuple(output[0].param_limits[i]) for i in range(parameter_truth.shape[0])]\n",
    "print(optimisation_bounds)\n",
    "optimisation_bounds_unit_cube = [(1.e-7, 1. - 1.e-7) for i in range(parameter_truth.shape[0] - 2)]\n",
    "print(optimisation_bounds_unit_cube)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integration_bounds = [[-0.2, 0.2], [0.85, 1.05]]\n",
    "\n",
    "#parameter_truth = parameter_truth * 1.01\n",
    "#print(parameter_truth)\n",
    "#parameter_truth_unit_cube = map_to_unit_cube(parameter_truth, output[0].param_limits)\n",
    "parameter_truth_unit_cube = 1.e-7 + npr.rand(5) * (1. - 2.e-7)\n",
    "print(parameter_truth_unit_cube)\n",
    "\n",
    "def likelihood_function(parameter_vector):\n",
    "    print(parameter_vector, map_from_unit_cube(parameter_vector, output[0].param_limits[2:]))\n",
    "    likelihood_evaluation = -1. * output[0].log_likelihood_marginalised_mean_flux(map_from_unit_cube(parameter_vector, output[0].param_limits[2:]), integration_bounds=integration_bounds)\n",
    "    print(likelihood_evaluation)\n",
    "    return likelihood_evaluation\n",
    "\n",
    "#acquisition_optimisation = spo.minimize(likelihood_function, parameter_truth_unit_cube, bounds=optimisation_bounds_unit_cube, options={'disp': True})\n",
    "acquisition_optimisation = spo.basinhopping(likelihood_function, parameter_truth_unit_cube, minimizer_kwargs={'bounds': optimisation_bounds_unit_cube, 'options': {'disp': True}}, disp=True)\n",
    "\n",
    "print(acquisition_optimisation.x)\n",
    "print(acquisition_optimisation.success)\n",
    "print(acquisition_optimisation.message)\n",
    "\n",
    "print(map_from_unit_cube(acquisition_optimisation.x, output[0].param_limits[2:]))\n",
    "#print(map_from_unit_cube(acquisition_optimisation.x, output[0].param_limits) - parameter_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_instance.close()\n",
    "del pool_instance\n",
    "\n",
    "n_process = 8\n",
    "\n",
    "integration_bounds = [[-0.2, 0.2], [0.85, 1.05]]\n",
    "\n",
    "def likelihood_function(parameter_vector):\n",
    "    #print(parameter_vector, map_from_unit_cube(parameter_vector, output[0].param_limits[2:]))\n",
    "    likelihood_evaluation = -1. * output[0].log_likelihood_marginalised_mean_flux(map_from_unit_cube(parameter_vector, output[0].param_limits[2:]), integration_bounds=integration_bounds)\n",
    "    #print(likelihood_evaluation)\n",
    "    return likelihood_evaluation\n",
    "\n",
    "def optimisation_function(optimisation_arguments):\n",
    "    false_number, parameter_truth_unit_cube = optimisation_arguments\n",
    "\n",
    "    acquisition_optimisation = spo.minimize(likelihood_function, parameter_truth_unit_cube, bounds=optimisation_bounds_unit_cube, options={'disp': False})\n",
    "    #print(acquisition_optimisation.success)\n",
    "    #print(acquisition_optimisation.message)\n",
    "    return acquisition_optimisation.x\n",
    "#acquisition_optimisation = spo.basinhopping(likelihood_function, parameter_truth_unit_cube, minimizer_kwargs={'bounds': optimisation_bounds_unit_cube, 'options': {'disp': True}}, disp=True)\n",
    "\n",
    "optimisation_arguments_list = [(0., 1.e-7 + npr.rand(5) * (1. - 2.e-7)) for i in range(n_process)]\n",
    "print(optimisation_arguments_list)\n",
    "pool_instance = mu.Pool(n_process)\n",
    "optimisation_results = pool_instance.map(optimisation_function, optimisation_arguments_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corner_plot_labels = [r'$n_s$', r'$A_s$', 'heat slope', 'heat amp', 'hub']\n",
    "\n",
    "co.corner(posterior_samples[:, 2:], labels=corner_plot_labels, truths=np.concatenate(([], map_from_unit_cube(acquisition_optimisation.x, output[0].param_limits[2:]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[-5.86448758e-02  9.64476445e-01  9.88091992e-01  2.40207473e-09\n",
    "  1.30284380e-01  1.06729539e+00  6.91094030e-01]\n",
    "[-6.73717605e-02  9.79216137e-01  9.86009810e-01  2.36946453e-09\n",
    "  1.88449411e-01  9.78980755e-01  6.89627409e-01]\n",
    "[-7.77305181e-03  9.28751149e-01  9.89338079e-01  2.24040312e-09\n",
    " -1.96653971e-02  1.28341469e+00  6.88152784e-01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[9.92761335e-01 2.42336688e-09 3.53231102e-02 1.24026185e+00\n",
    " 6.90070110e-01]\n",
    "[9.98922713e-01 1.78991408e-09 2.00561918e-01 8.91035270e-01\n",
    " 7.16109410e-01]\n",
    "[1.01805673e+00 1.55893077e-09 3.39285232e-01 8.39858390e-01\n",
    " 7.28723550e-01]\n",
    "[ 9.76096007e-01  2.27948154e-09 -2.11387489e-01  1.32066491e+00\n",
    "  6.88386399e-01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "multiprocessing.set_start_method('forkserver', force=True)\n",
    "from test_functions import *\n",
    "#import GPy\n",
    "#import emcee\n",
    "\n",
    "\n",
    "#def square(x):\n",
    "#    print(x)\n",
    "#    print(np.linalg.pinv(np.eye(2)))\n",
    "#    return np.sum(x**2+ 2*x)\n",
    "\n",
    "#def minimize(args):\n",
    "#    f,x = args\n",
    "#    res = optimize.minimize(f, x, method = 'L-BFGS-B')\n",
    "#    return res.x\n",
    "\n",
    "x = np.random.rand(2,10)\n",
    "\n",
    "args = [(square, x[i], output[0]) for i in range(2)]\n",
    "print(args)\n",
    "p = Pool(2)\n",
    "p.map(minimize,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mg\n",
    "mg.set_start_method('forkserver', force=True)\n",
    "\n",
    "import acquisition as ac\n",
    "\n",
    "n_parameters = 3\n",
    "n_process = 20\n",
    "\n",
    "starting_positions = 1.e-7 + npr.rand(n_process, n_parameters - 2) * (1. - 2.e-7)\n",
    "optimisation_bounds = [(1.e-7, 1. - 1.e-7) for i in range(n_parameters - 2)]\n",
    "#integration_bounds = [list(output[0].param_limits[0]), list(output[0].param_limits[1])]\n",
    "integration_bounds = [[-0.005, 0.005], [0.948, 0.952]]\n",
    "argument_list = [(starting_positions[i], output[0], optimisation_bounds, 0., 1., integration_bounds) for i in range(n_process)]\n",
    "\n",
    "pool_instance = mg.Pool(n_process)\n",
    "optimisation_output = pool_instance.map(ac.optimise_acquisition_function_parallel, argument_list)\n",
    "\n",
    "[print(map_from_unit_cube(optimisation_output[i].x, output[0].param_limits[2:])) for i in range(n_process)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "[print(optimisation_output[i].fun) for i in range(n_process)]\n",
    "\n",
    "[print(map_from_unit_cube(starting_positions[i], output[0].param_limits[2:])) for i in range(n_process)]\n",
    "\n",
    "best_process = np.argmin(np.array([optimisation_output[i].fun for i in range(n_process)]))\n",
    "print(best_process, map_from_unit_cube(optimisation_output[best_process].x, output[0].param_limits[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy import optimize\n",
    "#from multiprocessing import Pool\n",
    "#import multiprocessing\n",
    "#multiprocessing.set_start_method('forkserver')\n",
    "\n",
    "n_process = 1\n",
    "n_total_parameters = 3\n",
    "n_parameters = 3\n",
    "\n",
    "output[0].random_function = 1.\n",
    "\n",
    "class FunctionClass(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def function_evaluation(self, parameters):\n",
    "        #return np.sum(parameters**2+ 2*parameters)\n",
    "        #return output[0].random_function\n",
    "        print('Evaluating likelihood function')\n",
    "        tau0_factors = mflux.mean_flux_slope_to_factor(output[0].zout, parameters[0])\n",
    "        emulator_output = (output[0].gpemu.kf, output[0].gpemu.nk, output[0].gpemu.nz, output[0].gpemu.coreg)\n",
    "        emulator_output2 = (output[0].gpemu.gps[0].params, output[0].gpemu.gps[0].param_limits, output[0].gpemu.gps[0].intol, output[0].gpemu.gps[0]._test_interp, output[0].gpemu.gps[0].coreg)\n",
    "        emulator_output3 = (output[0].gpemu.gps[0].scalefactors, output[0].gpemu.gps[0].paramzero)\n",
    "        parameters_unit_cube = map_to_unit_cube(parameters[1:], output[0].gpemu.gps[0].param_limits)\n",
    "        numpy_output = np.linalg.pinv(np.eye(2))\n",
    "        #emulator_output4 = output[0].gpemu.gps[0].gp.optimize(messages=True)\n",
    "        #.predict(parameters_unit_cube.reshape(1, -1))\n",
    "        #emulator_output2 = output[0].gpemu.gps[0].predict(parameters[1:].reshape(1, -1))\n",
    "        #function_predicted, function_std = output[0].gpemu.predict(np.array(parameters[1:]).reshape(1, -1), tau0_factors=tau0_factors)\n",
    "        #full_output = output[0].likelihood(parameters)\n",
    "        print('Finished evaluating likelihood function')\n",
    "        #full_output = output[0].get_BOSS_covariance_single_z(output[0].zout[0])\n",
    "        #full_output = output[0].\n",
    "        #print(full_output)\n",
    "        full_output = 1.\n",
    "        return np.mean(full_output)\n",
    "\n",
    "function_class_instance = FunctionClass()\n",
    "\n",
    "def optimisation_function(parameter_vector):\n",
    "    print('parameter_vector =', parameter_vector)\n",
    "    #eturn np.sum(parameter_vector**2+ 2*parameter_vector)\n",
    "    return function_class_instance.function_evaluation(parameter_vector)\n",
    "    #return output[0].random_function\n",
    "    #return -1. * output[0].likelihood(parameter_vector)\n",
    "    #return -1. * output[0].log_likelihood_marginalised_mean_flux(parameter_vector)\n",
    "\n",
    "def get_prior_limits():\n",
    "    #prior_limits = np.ones((5, 2))\n",
    "    #prior_limits[:, 0] *= -1.5\n",
    "    #prior_limits[:, 1] *= -0.5\n",
    "    #return prior_limits\n",
    "    return output[0].param_limits[n_total_parameters - n_parameters:]\n",
    "\n",
    "def get_optimisation_function(x):\n",
    "    print('x in get_optimisation_function =', x)\n",
    "    #prior_limits = np.ones((5, 2))\n",
    "    #prior_limits[:, 0] *= -1.5\n",
    "    #prior_limits[:, 1] *= -0.5\n",
    "    prior_limits = get_prior_limits()\n",
    "    x_unscaled = map_from_unit_cube(x, prior_limits)\n",
    "    print('x_unscaled in get_optimisation_function =', x_unscaled)\n",
    "    return optimisation_function(x_unscaled)\n",
    "    #return np.sum(x_unscaled**2+ 2*x_unscaled)\n",
    "    #return output[0].log_likelihood_marginalised_mean_flux(x_unscaled)\n",
    "\n",
    "def minimize(args):\n",
    "    x_bounds = [[1.e-7, 1. - 1.e-7] for i in range(n_parameters)] #For unit hypercube\n",
    "    f, x = args\n",
    "    res = spo.minimize(f, x, method = 'L-BFGS-B', bounds=x_bounds, options={'disp': True})\n",
    "    return res.x\n",
    "\n",
    "x = 1.e-7 + np.random.rand(n_process, n_parameters) * (1. - 2.e-7) #Starting positions\n",
    "print('x (starting positions) =', x)\n",
    "\n",
    "args = [(get_optimisation_function, x[i]) for i in range(n_process)]\n",
    "p = mu.Pool(n_process)\n",
    "optimisation_result = p.map(minimize, args)\n",
    "#optimisation_result = list(map(minimize, args)) #p.\n",
    "print('optimisation_result =', optimisation_result)\n",
    "\n",
    "optimisation_result_rescaled = [map_from_unit_cube(optimisation_result[i], get_prior_limits()) for i in range(n_process)]\n",
    "print('optimisation_result_rescaled =', optimisation_result_rescaled)\n",
    "print(np.array(optimisation_result) - np.array(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(minimize, args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0].gpemu.gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print([i for i in locals() if i in sys.modules.keys()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
