{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run /home/keir/Software/lya_emulator/main.py /share/hypatia/sbird/Lya_Boss /home/keir/Plots/Emulator hires_s8_new /home/keir/Data/emulator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run /home/keir/Software/lya_emulator/main.py /home/keir/Data/emulator /home/keir/Plots/Emulator hot_cold_validation /home/keir/Data/emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import multiprocessing as mu\n",
    "#import corner as co\n",
    "#import seaborn as sb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = np.loadtxt('/home/keir/Data/emulator/AA0.97BB1.3_chain_hot_cold_training3_rescale_2000.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0].add_to_emulator_training_set(np.array([[0.95],]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0].gpemu.gps[0].gp.X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_process = 10\n",
    "n_parameters = 3\n",
    "n_marginalised_parameters = 2\n",
    "\n",
    "#optimisation_bounds_unscaled = np.array([[0.81, 1.], [1.3e-9, 2.9e-9], [-0.44, 0.44], [0.56, 1.4], [0.61, 0.79]]) #Convex hull_0\n",
    "#optimisation_bounds_unscaled = np.array([[0.825, 1.], [1.4e-9, 2.8e-9], [-0.385, 0.385], [0.615, 1.35], [0.62, 0.78]]) #Convex hull_1\n",
    "#optimisation_bounds_unscaled = np.array([[0.84, 1.], [1.5e-9, 2.7e-9], [-0.33, 0.33], [0.67, 1.3], [0.63, 0.77]]) #Convex hull_2\n",
    "#optimisation_bounds_unscaled = np.array([[0.915, 0.985], [1.5e-9, 2.5e-9], [-0.2, 0.2], [0.8, 1.3], [0.65, 0.73]]) #Edge\n",
    "#optimisation_bounds_unscaled = np.array([[0.93, 0.98], [1.5e-9, 2.5e-9], [-0.2, 0.2], [0.9, 1.3], [0.655, 0.725]]) #4s\n",
    "\n",
    "#refinement_big\n",
    "optimisation_bounds_unscaled = np.array([[0.9, 1.],]) #CH2\n",
    "print(optimisation_bounds_unscaled)\n",
    "\n",
    "optimisation_bounds_array = np.zeros_like(optimisation_bounds_unscaled)\n",
    "optimisation_bounds_array[:, 0] = map_to_unit_cube(optimisation_bounds_unscaled[:, 0], output[0].param_limits[n_marginalised_parameters:])\n",
    "optimisation_bounds_array[:, 1] = map_to_unit_cube(optimisation_bounds_unscaled[:, 1], output[0].param_limits[n_marginalised_parameters:])\n",
    "\n",
    "#optimisation_bounds_array = np.ones((n_parameters - n_marginalised_parameters, 2))\n",
    "#optimisation_bounds_array[:, 0] *= 1.e-7\n",
    "#optimisation_bounds_array[:, 1] *= 1. - 1.e-7\n",
    "\n",
    "print(optimisation_bounds_array)\n",
    "optimisation_bounds = [tuple(optimisation_bounds_array[i]) for i in range(n_parameters - n_marginalised_parameters)]\n",
    "print(optimisation_bounds)\n",
    "\n",
    "starting_positions = np.array([npr.uniform(low=optimisation_bounds_array[:, 0], high=optimisation_bounds_array[:, 1]) for i in range(n_process)])\n",
    "#print(starting_positions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mg\n",
    "mg.set_start_method('forkserver', force=True)\n",
    "\n",
    "import acquisition as ac\n",
    "\n",
    "#starting_positions = 1.e-7 + npr.rand(n_process, n_parameters - n_marginalised_parameters) * (1. - 2.e-7)\n",
    "#optimisation_bounds = [(1.e-7, 1. - 1.e-7) for i in range(n_parameters - n_marginalised_parameters)]\n",
    "#integration_bounds = [list(output[0].param_limits[0]), list(output[0].param_limits[1])]\n",
    "#integration_bounds = [[-0.05, 0.1], [0.92, 1.02]]\n",
    "#integration_bounds = [[-0.04, 0.1], [0.96, 1.02]]\n",
    "integration_bounds = [[-0.04, 0.04], [0.94, 0.96]]\n",
    "argument_list = [(starting_positions[i], output[0], optimisation_bounds, 1., None, integration_bounds) for i in range(n_process)]\n",
    "\n",
    "pool_instance = mg.Pool(n_process)\n",
    "optimisation_output = pool_instance.map(ac.optimise_acquisition_function_parallel, argument_list)\n",
    "\n",
    "[print(map_from_unit_cube(optimisation_output[i].x, output[0].param_limits[n_marginalised_parameters:])) for i in range(n_process)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[print(optimisation_output[i].fun) for i in range(n_process)]\n",
    "\n",
    "[print(map_from_unit_cube(starting_positions[i], output[0].param_limits[n_marginalised_parameters:])) for i in range(n_process)]\n",
    "\n",
    "best_process = np.argmin(np.array([optimisation_output[i].fun for i in range(n_process)]))\n",
    "print(best_process, map_from_unit_cube(optimisation_output[best_process].x, output[0].param_limits[n_marginalised_parameters:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import corner as co\n",
    "\n",
    "corner_plot_labels = [r'$d\\tau_0$', r'$\\tau_0$', r'$n_s$', r'$A_s$', 'heat slope', 'heat amp', 'hub']\n",
    "\n",
    "co.corner(posterior_samples[:, n_marginalised_parameters:], labels=corner_plot_labels[n_marginalised_parameters:], truths=np.concatenate(([], map_from_unit_cube(optimisation_output[best_process].x, output[0].param_limits[n_marginalised_parameters:]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0].param_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisition_function_tau0_amp = output.make_grid_acquisition_function(1, 2, samples=30000, nu=1., exploitation_weight=0.)\n",
    "acquisition_function_tau0_amp[acquisition_function_tau0_amp == 0.] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisition_function_tau0_amp_exploit = output.make_grid_acquisition_function(0, 2, samples=1000, nu=0., exploitation_weight=1.)\n",
    "acquisition_function_tau0_amp_exploit[acquisition_function_tau0_amp_exploit == 0.] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contour(np.log10(acquisition_function_tau0_amp).T, 100, extent=[0.75, 1.25, 0.8, 1.2], origin='image')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.exp(acquisition_function_tau0_amp).T, extent=[-0.25, 0.25, 0.8, 1.2])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 18))\n",
    "plt.imshow(np.exp(acquisition_function_tau0_amp_exploit - np.nanmax(acquisition_function_tau0_amp_exploit)).T, extent=[-0.25, 0.25, 0.8, 1.2])\n",
    "plt.colorbar()\n",
    "#plt.scatter(0.95, 0.95, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisition_function_exploit = output.acquisition_function_GP_UCB_marginalised_mean_flux(np.array([0.95,]), nu=1., exploitation_weight=0.)\n",
    "acquisition_function_exploit = output.acquisition_function_GP_UCB_marginalised_mean_flux(np.array([0.9,]), nu=1., exploitation_weight=0.)\n",
    "acquisition_function_exploit = output.acquisition_function_GP_UCB_marginalised_mean_flux(np.array([1.,]), nu=1., exploitation_weight=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisition_function_exploit = output.acquisition_function_GP_UCB_marginalised_mean_flux(np.array([0.95,]), nu=1., exploitation_weight=1.)\n",
    "acquisition_function_exploit = output.acquisition_function_GP_UCB_marginalised_mean_flux(np.array([0.95,]), nu=0., exploitation_weight=1.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output[0].acquisition_function_GP_UCB_marginalised_mean_flux(np.array([0.81,]), nu=1., exploitation_weight=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(output[0]._get_emulator_error_averaged_mean_flux(np.array([0.81,]))))\n",
    "\n",
    "_ = output[0].likelihood(np.array([0., 0.95, 0.81]))\n",
    "print(np.mean(output[0].emulated_flux_power_std[0]))\n",
    "\n",
    "print(np.mean(output[0].emulated_flux_power_std[0]) / np.mean(output[0].emulated_flux_power[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.cur_results.flatchain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.cur_results.get_lnprob(np.array([0., 0.95, 0.95]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(posterior_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_output = sb.kdeplot(posterior_samples[:, 2]).get_lines()[0].get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_output = plt.hist(posterior_samples[:, 2], bins='auto', normed=True, histtype='step', log=True)\n",
    "print(histogram_output)\n",
    "plt.axvline(x=0.92)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(histogram_output[0].shape)\n",
    "print(histogram_output[1].shape)\n",
    "print(histogram_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#n_samples = 200\n",
    "parameter_samples = (histogram_output[1][:-1] + histogram_output[1][1:]) / 2. #np.linspace(output[0].param_limits[2, 0], output[0].param_limits[2, 1], num=n_samples)\n",
    "acquisition_function_exploit_array = np.zeros_like(parameter_samples)\n",
    "for i in range(parameter_samples.shape[0]):\n",
    "    acquisition_function_exploit_array[i] = output[0].acquisition_function_GP_UCB_marginalised_mean_flux(np.array([parameter_samples[i],]), nu=1., exploitation_weight=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#n_samples = 200\n",
    "parameter_samples2 = histogram_output[0] #np.linspace(output[0].param_limits[2, 0], output[0].param_limits[2, 1], num=n_samples)\n",
    "acquisition_function_exploit_array2 = np.zeros_like(parameter_samples2)\n",
    "for i in range(parameter_samples2.shape[0]):\n",
    "    acquisition_function_exploit_array2[i] = output[0].acquisition_function_GP_UCB_marginalised_mean_flux(np.array([parameter_samples2[i],]), nu=1., exploitation_weight=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(parameter_samples2, np.log(histogram_output[1] / np.max(histogram_output[1])))\n",
    "plt.xlim([0.89, 1.11])\n",
    "plt.ylim([-2.5, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(parameter_samples2, 100*acquisition_function_exploit_array2[:parameter_samples2.shape[0]])\n",
    "plt.axvline(x=0.9, color='black', ls=':')\n",
    "plt.axvline(x=1., color='black', ls=':')\n",
    "plt.axvline(x=1.1, color='black', ls=':')\n",
    "plt.xlim([0.89, 1.11])\n",
    "plt.ylim([0., 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(parameter_samples2, np.log(histogram_output[1] / np.max(histogram_output[1])), label=r'Exploitation term')\n",
    "plt.plot(parameter_samples2, 100*acquisition_function_exploit_array2[:parameter_samples2.shape[0]], label=r'Exploration term')\n",
    "plt.plot(parameter_samples2, np.log(histogram_output[1] / np.max(histogram_output[1])) + 100.*acquisition_function_exploit_array2[:parameter_samples2.shape[0]], label=r'GP-UCB acquisition function')\n",
    "\n",
    "plt.legend(frameon=False)\n",
    "#plt.axvline(x=0.9, color='black', ls=':')\n",
    "plt.axvline(x=0.92, color='blue', ls=':')\n",
    "plt.axvline(x=0.925, color='green', ls=':')\n",
    "#plt.axvline(x=0.95, color='black', ls=':')\n",
    "plt.xlim([0.89, 0.95])\n",
    "plt.ylim([-0.1, 0.2])\n",
    "plt.xlabel(r'heat amp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0].param_limits[0] = np.array([-0.24, 0.24])\n",
    "print(output[0].param_limits)\n",
    "output[0].log_likelihood_marginalised_mean_flux(np.array([0.95,]), integration_method='Monte-Carlo', integration_options=6000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output[0].param_limits[0] = np.array([-0.007, 0.007])\n",
    "#output[0].param_limits[1] = np.array([0.948, 0.952])\n",
    "\n",
    "integration_bounds = [[-0.08, 0.08], [0.936, 0.964]]\n",
    "\n",
    "#mmh.dps = 50\n",
    "integration_instance = mmh.calculus.quadrature.GaussLegendre\n",
    "print(integration_instance)\n",
    "\n",
    "likelihood_marginalised = np.zeros(10)\n",
    "exploration_term = np.zeros_like(likelihood_marginalised)\n",
    "#parameter_samples = np.linspace(output[0].param_limits[2, 0] + 0.01, output[0].param_limits[2, 1], num=likelihood_marginalised.shape[0], endpoint=False)\n",
    "parameter_samples = np.linspace(0.912, 0.928, num=likelihood_marginalised.shape[0])\n",
    "for i in range(likelihood_marginalised.shape[0]):\n",
    "    parameter_vector = np.array([parameter_samples[i],])\n",
    "    #likelihood_marginalised[i] = output[0].log_likelihood_marginalised_mean_flux(np.array([parameter_samples[i],]), integration_method='Quadrature', integration_options=integration_instance)\n",
    "    likelihood_marginalised[i] = output[0].acquisition_function_GP_UCB_marginalised_mean_flux(parameter_vector, nu=0., integration_options='gauss-legendre', integration_bounds=integration_bounds)\n",
    "    exploration_term[i] = output[0].acquisition_function_GP_UCB_marginalised_mean_flux(parameter_vector, exploitation_weight=None, nu=1.e4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(parameter_samples, likelihood_marginalised)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(parameter_samples, likelihood_marginalised - np.nanmax(likelihood_marginalised))\n",
    "plt.scatter(parameter_samples, exploration_term, color='red')\n",
    "plt.plot(histogram_output[0], np.log(histogram_output[1] / np.nanmax(histogram_output[1])), color='blue')\n",
    "plt.axvline(x=0.92)\n",
    "plt.xlim([0.89, 0.95])\n",
    "plt.ylim([-0.2, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(parameter_samples, likelihood_marginalised - np.nanmax(likelihood_marginalised), color='red')\n",
    "#sb.kdeplot(posterior_samples[:, 2])\n",
    "plt.plot(histogram_output[0], np.log(histogram_output[1] / np.nanmax(histogram_output[1])))\n",
    "plt.axvline(x=0.92, color='black')\n",
    "plt.xlim([0.91, 0.93])\n",
    "plt.ylim([-0.01, 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(parameter_samples, np.exp(likelihood_marginalised - np.nanmax(likelihood_marginalised)), color='red')\n",
    "#sb.kdeplot(posterior_samples[:, 2])\n",
    "plt.plot(histogram_output[0], histogram_output[1] / np.nanmax(histogram_output[1]))\n",
    "plt.axvline(x=0.92, color='black')\n",
    "plt.xlim([0.8, 1.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integration_bounds = [[-0.08, 0.08], [0.936, 0.964]]\n",
    "\n",
    "acquisition_optimisation = output[0].optimise_acquisition_function(np.array([1.1,]), optimisation_bounds=[(0.81, 1.19),], nu=0., integration_bounds=integration_bounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acquisition_optimisation.x)\n",
    "print(acquisition_optimisation.success)\n",
    "print(acquisition_optimisation.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_truth = np.array([0., 0.95, 0.975, 2.25e-09, 0.08333333333333326, 0.9166666666666666, 0.6916666666666667])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimisation_bounds = [tuple(output[0].param_limits[i]) for i in range(parameter_truth.shape[0])]\n",
    "print(optimisation_bounds)\n",
    "optimisation_bounds_unit_cube = [(1.e-7, 1. - 1.e-7) for i in range(parameter_truth.shape[0] - 2)]\n",
    "print(optimisation_bounds_unit_cube)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integration_bounds = [[-0.2, 0.2], [0.85, 1.05]]\n",
    "\n",
    "#parameter_truth = parameter_truth * 1.01\n",
    "#print(parameter_truth)\n",
    "#parameter_truth_unit_cube = map_to_unit_cube(parameter_truth, output[0].param_limits)\n",
    "parameter_truth_unit_cube = 1.e-7 + npr.rand(5) * (1. - 2.e-7)\n",
    "print(parameter_truth_unit_cube)\n",
    "\n",
    "def likelihood_function(parameter_vector):\n",
    "    print(parameter_vector, map_from_unit_cube(parameter_vector, output[0].param_limits[2:]))\n",
    "    likelihood_evaluation = -1. * output[0].log_likelihood_marginalised_mean_flux(map_from_unit_cube(parameter_vector, output[0].param_limits[2:]), integration_bounds=integration_bounds)\n",
    "    print(likelihood_evaluation)\n",
    "    return likelihood_evaluation\n",
    "\n",
    "#acquisition_optimisation = spo.minimize(likelihood_function, parameter_truth_unit_cube, bounds=optimisation_bounds_unit_cube, options={'disp': True})\n",
    "acquisition_optimisation = spo.basinhopping(likelihood_function, parameter_truth_unit_cube, minimizer_kwargs={'bounds': optimisation_bounds_unit_cube, 'options': {'disp': True}}, disp=True)\n",
    "\n",
    "print(acquisition_optimisation.x)\n",
    "print(acquisition_optimisation.success)\n",
    "print(acquisition_optimisation.message)\n",
    "\n",
    "print(map_from_unit_cube(acquisition_optimisation.x, output[0].param_limits[2:]))\n",
    "#print(map_from_unit_cube(acquisition_optimisation.x, output[0].param_limits) - parameter_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_instance.close()\n",
    "del pool_instance\n",
    "\n",
    "n_process = 8\n",
    "\n",
    "integration_bounds = [[-0.2, 0.2], [0.85, 1.05]]\n",
    "\n",
    "def likelihood_function(parameter_vector):\n",
    "    #print(parameter_vector, map_from_unit_cube(parameter_vector, output[0].param_limits[2:]))\n",
    "    likelihood_evaluation = -1. * output[0].log_likelihood_marginalised_mean_flux(map_from_unit_cube(parameter_vector, output[0].param_limits[2:]), integration_bounds=integration_bounds)\n",
    "    #print(likelihood_evaluation)\n",
    "    return likelihood_evaluation\n",
    "\n",
    "def optimisation_function(optimisation_arguments):\n",
    "    false_number, parameter_truth_unit_cube = optimisation_arguments\n",
    "\n",
    "    acquisition_optimisation = spo.minimize(likelihood_function, parameter_truth_unit_cube, bounds=optimisation_bounds_unit_cube, options={'disp': False})\n",
    "    #print(acquisition_optimisation.success)\n",
    "    #print(acquisition_optimisation.message)\n",
    "    return acquisition_optimisation.x\n",
    "#acquisition_optimisation = spo.basinhopping(likelihood_function, parameter_truth_unit_cube, minimizer_kwargs={'bounds': optimisation_bounds_unit_cube, 'options': {'disp': True}}, disp=True)\n",
    "\n",
    "optimisation_arguments_list = [(0., 1.e-7 + npr.rand(5) * (1. - 2.e-7)) for i in range(n_process)]\n",
    "print(optimisation_arguments_list)\n",
    "pool_instance = mu.Pool(n_process)\n",
    "optimisation_results = pool_instance.map(optimisation_function, optimisation_arguments_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corner_plot_labels = [r'$n_s$', r'$A_s$', 'heat slope', 'heat amp', 'hub']\n",
    "\n",
    "co.corner(posterior_samples[:, 2:], labels=corner_plot_labels, truths=np.concatenate(([], map_from_unit_cube(acquisition_optimisation.x, output[0].param_limits[2:]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[-5.86448758e-02  9.64476445e-01  9.88091992e-01  2.40207473e-09\n",
    "  1.30284380e-01  1.06729539e+00  6.91094030e-01]\n",
    "[-6.73717605e-02  9.79216137e-01  9.86009810e-01  2.36946453e-09\n",
    "  1.88449411e-01  9.78980755e-01  6.89627409e-01]\n",
    "[-7.77305181e-03  9.28751149e-01  9.89338079e-01  2.24040312e-09\n",
    " -1.96653971e-02  1.28341469e+00  6.88152784e-01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[9.92761335e-01 2.42336688e-09 3.53231102e-02 1.24026185e+00\n",
    " 6.90070110e-01]\n",
    "[9.98922713e-01 1.78991408e-09 2.00561918e-01 8.91035270e-01\n",
    " 7.16109410e-01]\n",
    "[1.01805673e+00 1.55893077e-09 3.39285232e-01 8.39858390e-01\n",
    " 7.28723550e-01]\n",
    "[ 9.76096007e-01  2.27948154e-09 -2.11387489e-01  1.32066491e+00\n",
    "  6.88386399e-01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "multiprocessing.set_start_method('forkserver', force=True)\n",
    "from test_functions import *\n",
    "#import GPy\n",
    "#import emcee\n",
    "\n",
    "\n",
    "#def square(x):\n",
    "#    print(x)\n",
    "#    print(np.linalg.pinv(np.eye(2)))\n",
    "#    return np.sum(x**2+ 2*x)\n",
    "\n",
    "#def minimize(args):\n",
    "#    f,x = args\n",
    "#    res = optimize.minimize(f, x, method = 'L-BFGS-B')\n",
    "#    return res.x\n",
    "\n",
    "x = np.random.rand(2,10)\n",
    "\n",
    "args = [(square, x[i], output[0]) for i in range(2)]\n",
    "print(args)\n",
    "p = Pool(2)\n",
    "p.map(minimize,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mg\n",
    "mg.set_start_method('forkserver', force=True)\n",
    "\n",
    "import acquisition as ac\n",
    "\n",
    "n_parameters = 3\n",
    "n_process = 20\n",
    "\n",
    "starting_positions = 1.e-7 + npr.rand(n_process, n_parameters - 2) * (1. - 2.e-7)\n",
    "optimisation_bounds = [(1.e-7, 1. - 1.e-7) for i in range(n_parameters - 2)]\n",
    "#integration_bounds = [list(output[0].param_limits[0]), list(output[0].param_limits[1])]\n",
    "integration_bounds = [[-0.005, 0.005], [0.948, 0.952]]\n",
    "argument_list = [(starting_positions[i], output[0], optimisation_bounds, 0., 1., integration_bounds) for i in range(n_process)]\n",
    "\n",
    "pool_instance = mg.Pool(n_process)\n",
    "optimisation_output = pool_instance.map(ac.optimise_acquisition_function_parallel, argument_list)\n",
    "\n",
    "[print(map_from_unit_cube(optimisation_output[i].x, output[0].param_limits[2:])) for i in range(n_process)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "[print(optimisation_output[i].fun) for i in range(n_process)]\n",
    "\n",
    "[print(map_from_unit_cube(starting_positions[i], output[0].param_limits[2:])) for i in range(n_process)]\n",
    "\n",
    "best_process = np.argmin(np.array([optimisation_output[i].fun for i in range(n_process)]))\n",
    "print(best_process, map_from_unit_cube(optimisation_output[best_process].x, output[0].param_limits[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy import optimize\n",
    "#from multiprocessing import Pool\n",
    "#import multiprocessing\n",
    "#multiprocessing.set_start_method('forkserver')\n",
    "\n",
    "n_process = 1\n",
    "n_total_parameters = 3\n",
    "n_parameters = 3\n",
    "\n",
    "output[0].random_function = 1.\n",
    "\n",
    "class FunctionClass(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def function_evaluation(self, parameters):\n",
    "        #return np.sum(parameters**2+ 2*parameters)\n",
    "        #return output[0].random_function\n",
    "        print('Evaluating likelihood function')\n",
    "        tau0_factors = mflux.mean_flux_slope_to_factor(output[0].zout, parameters[0])\n",
    "        emulator_output = (output[0].gpemu.kf, output[0].gpemu.nk, output[0].gpemu.nz, output[0].gpemu.coreg)\n",
    "        emulator_output2 = (output[0].gpemu.gps[0].params, output[0].gpemu.gps[0].param_limits, output[0].gpemu.gps[0].intol, output[0].gpemu.gps[0]._test_interp, output[0].gpemu.gps[0].coreg)\n",
    "        emulator_output3 = (output[0].gpemu.gps[0].scalefactors, output[0].gpemu.gps[0].paramzero)\n",
    "        parameters_unit_cube = map_to_unit_cube(parameters[1:], output[0].gpemu.gps[0].param_limits)\n",
    "        numpy_output = np.linalg.pinv(np.eye(2))\n",
    "        #emulator_output4 = output[0].gpemu.gps[0].gp.optimize(messages=True)\n",
    "        #.predict(parameters_unit_cube.reshape(1, -1))\n",
    "        #emulator_output2 = output[0].gpemu.gps[0].predict(parameters[1:].reshape(1, -1))\n",
    "        #function_predicted, function_std = output[0].gpemu.predict(np.array(parameters[1:]).reshape(1, -1), tau0_factors=tau0_factors)\n",
    "        #full_output = output[0].likelihood(parameters)\n",
    "        print('Finished evaluating likelihood function')\n",
    "        #full_output = output[0].get_BOSS_covariance_single_z(output[0].zout[0])\n",
    "        #full_output = output[0].\n",
    "        #print(full_output)\n",
    "        full_output = 1.\n",
    "        return np.mean(full_output)\n",
    "\n",
    "function_class_instance = FunctionClass()\n",
    "\n",
    "def optimisation_function(parameter_vector):\n",
    "    print('parameter_vector =', parameter_vector)\n",
    "    #eturn np.sum(parameter_vector**2+ 2*parameter_vector)\n",
    "    return function_class_instance.function_evaluation(parameter_vector)\n",
    "    #return output[0].random_function\n",
    "    #return -1. * output[0].likelihood(parameter_vector)\n",
    "    #return -1. * output[0].log_likelihood_marginalised_mean_flux(parameter_vector)\n",
    "\n",
    "def get_prior_limits():\n",
    "    #prior_limits = np.ones((5, 2))\n",
    "    #prior_limits[:, 0] *= -1.5\n",
    "    #prior_limits[:, 1] *= -0.5\n",
    "    #return prior_limits\n",
    "    return output[0].param_limits[n_total_parameters - n_parameters:]\n",
    "\n",
    "def get_optimisation_function(x):\n",
    "    print('x in get_optimisation_function =', x)\n",
    "    #prior_limits = np.ones((5, 2))\n",
    "    #prior_limits[:, 0] *= -1.5\n",
    "    #prior_limits[:, 1] *= -0.5\n",
    "    prior_limits = get_prior_limits()\n",
    "    x_unscaled = map_from_unit_cube(x, prior_limits)\n",
    "    print('x_unscaled in get_optimisation_function =', x_unscaled)\n",
    "    return optimisation_function(x_unscaled)\n",
    "    #return np.sum(x_unscaled**2+ 2*x_unscaled)\n",
    "    #return output[0].log_likelihood_marginalised_mean_flux(x_unscaled)\n",
    "\n",
    "def minimize(args):\n",
    "    x_bounds = [[1.e-7, 1. - 1.e-7] for i in range(n_parameters)] #For unit hypercube\n",
    "    f, x = args\n",
    "    res = spo.minimize(f, x, method = 'L-BFGS-B', bounds=x_bounds, options={'disp': True})\n",
    "    return res.x\n",
    "\n",
    "x = 1.e-7 + np.random.rand(n_process, n_parameters) * (1. - 2.e-7) #Starting positions\n",
    "print('x (starting positions) =', x)\n",
    "\n",
    "args = [(get_optimisation_function, x[i]) for i in range(n_process)]\n",
    "p = mu.Pool(n_process)\n",
    "optimisation_result = p.map(minimize, args)\n",
    "#optimisation_result = list(map(minimize, args)) #p.\n",
    "print('optimisation_result =', optimisation_result)\n",
    "\n",
    "optimisation_result_rescaled = [map_from_unit_cube(optimisation_result[i], get_prior_limits()) for i in range(n_process)]\n",
    "print('optimisation_result_rescaled =', optimisation_result_rescaled)\n",
    "print(np.array(optimisation_result) - np.array(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(minimize, args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0].gpemu.gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print([i for i in locals() if i in sys.modules.keys()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
